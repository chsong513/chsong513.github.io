<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
   <style>
      .left {
        float: left;
        width: 300px;
      }
      .right {
        float: right;
        margin-left: 300px;
      }
      a{TEXT-DECORATION:none}
      a:hover{TEXT-DECORATION:underline}

      .rotate {

        -webkit-transition: -webkit-transform 2s;
      }

      .rotate:hover {
        -webkit-transform: rotate(360deg);
      }

      .tag-list-link {
        display: inline-block;
        vertical-align: middle;
        text-decoration: none;
        height: 30px;
        line-height: 30px;
        padding: 0 15px;
        font-size: 1.5rem;
        border-radius: 15px;
        background-color: #5d5a5a;
        color: #fff;
        box-shadow: 0 3px 5px rgba(0,0,0,.12);
        transition: .2s;
      }

      .article-meta{
        display: flex;
        color: #5c6b72;
      }

</style>


    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Deep Knowledge Tracing [Pytorch] |  
  </title>
  
  <link rel="shortcut icon" href="/logo.ico" />
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<script src="/js/pace.min.js"></script>

  
<script src="/js/clicklove.js"></script>

  
<script src="/fancybox/jquery.fancybox.min.js"></script>


  

  

  
  <script data-ad-client="ca-pub-7950001743265524" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

  <meta name="baidu_ssp_verify" content="4bf2429568b907ea4e093a35a1731868">

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="null" type="application/atom+xml">
</head>


</html>

<body>
  <div id="app">
    <main class="content">
      <section class="outer">
  <article id="post-20201124_DKT-Pytorch" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Deep Knowledge Tracing [Pytorch]
</h1>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/20201124_DKT-Pytorch/index.html" class="article-date">
  <time datetime="2020-11-24T10:12:17.000Z" itemprop="datePublished">2020-11-24</time>&nbsp;&nbsp;&nbsp;
</a>

      
  作者: 小解子

&nbsp;&nbsp;



    </div>
    

    
    
    <div class="tocbot"></div>





    
    <div class="article-entry" id="jiedu" itemprop="articleBody">
      
      <p><img src="http://img.chsong.live/Blogs/DKT-pytorch/1.png-o" alt="DKT"></p>
<p>知识追踪（Knowledge Tracing）是根据学生过去的答题情况对学生的知识掌握情况进行建模，从而得到学生当前知识状态表示的一种技术。将深度学习的方法引入知识追踪最早出现于发表在NeurIPS 2015上的一篇论文《Deep Knowledge Tracing》，作者来自斯坦福大学。在这篇论文中，作者提出了使用深度知识追踪（Deep Knowledge Tracing, DKT）的概念，利用RNN对学生的学习情况进行建模，之后引出了一系列工作，2019年已经有使用Transformer代替RNN和LSTM并且达到了SOTA的论文。DKT作为知识追踪模型深度化的开山之作，在几乎所有的深度知识追踪模型中都作为baseline，而DKT作者给出的模型实现是基于lua语言的，为了能够让更多的研究人员更方便的使用，这里给出一种python的实现，采用的是pytorch框架。</p>
<a id="more"></a>

<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>模型代码已经发布在github上，可点击<a href="https://github.com/chsong513/DeepKnowledgeTracing-DKT-Pytorch" target="_blank" rel="noopener">这里</a>查看和下载具体代码。</p>
<p>或者可以直接通过如下命令直接下载到本地：</p>
<blockquote>
<p>git clone <a href="https://github.com/chsong513/DeepKnowledgeTracing-DKT-Pytorch.git" target="_blank" rel="noopener">https://github.com/chsong513/DeepKnowledgeTracing-DKT-Pytorch.git</a></p>
</blockquote>
<p>具体运行和使用方法参考GitHub项目上ReadMe。</p>
<h2 id="项目结构-DKT"><a href="#项目结构-DKT" class="headerlink" title="项目结构-DKT"></a>项目结构-DKT</h2><p>在DKT文件夹下包括两个文件夹：KTDataset和KnowledgeTracing。</p>
<p><img src="http://img.chsong.live/Blogs/DKT-pytorch/2.png-o" alt=""></p>
<h3 id="数据集-KTDataset"><a href="#数据集-KTDataset" class="headerlink" title="数据集-KTDataset"></a>数据集-KTDataset</h3><p><img src="http://img.chsong.live/Blogs/DKT-pytorch/4.png-o" alt=""></p>
<p>KTDataset文件夹下有6个常用的知识追踪数据集，数据都已经处理成三行格式：</p>
<blockquote>
<p>第一行：答题数<br>第二行：题目编号<br>第三行：答题结果，0表示错，1表示对</p>
</blockquote>
<p>举例：<br><img src="http://img.chsong.live/Blogs/DKT-pytorch/3.png-o" alt=""></p>
<p>Note：可根据需要，按照数据格式自行添加新的数据集。</p>
<h3 id="模型结构-KnowledgeTracing"><a href="#模型结构-KnowledgeTracing" class="headerlink" title="模型结构-KnowledgeTracing"></a>模型结构-KnowledgeTracing</h3><p><img src="http://img.chsong.live/Blogs/DKT-pytorch/5.png-o" alt=""></p>
<p>模型的整个流程都在KnowledgeTracing目录下，包括模型、参数设置、数据处理、模型训练和评估，分别在四个子目录下：model， Constant，data，evaluation。</p>
<h4 id="参数设置-Constant"><a href="#参数设置-Constant" class="headerlink" title="参数设置-Constant"></a>参数设置-Constant</h4><p>Constant下主要设置一些参数和超参数，超参数也分为四大块：数据集存储路径、数据集、题目数、模型超参数。</p>
<p>数据集存储路径</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Dpath = <span class="string">'../../KTDataset'</span></span><br></pre></td></tr></table></figure>
<p>数据集：一共包括6个数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">datasets = &#123;</span><br><span class="line">    <span class="string">'assist2009'</span> : <span class="string">'assist2009'</span>,</span><br><span class="line">    <span class="string">'assist2015'</span> : <span class="string">'assist2015'</span>,</span><br><span class="line">    <span class="string">'assist2017'</span> : <span class="string">'assist2017'</span>,</span><br><span class="line">    <span class="string">'static2011'</span> : <span class="string">'static2011'</span>,</span><br><span class="line">    <span class="string">'kddcup2010'</span> : <span class="string">'kddcup2010'</span>,</span><br><span class="line">    <span class="string">'synthetic'</span> : <span class="string">'synthetic'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>题目数：表示每个数据集里面题目的数量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">numbers = &#123;</span><br><span class="line">    <span class="string">'assist2009'</span> : <span class="number">124</span>,  </span><br><span class="line">    <span class="string">'assist2015'</span> : <span class="number">100</span>,</span><br><span class="line">    <span class="string">'assist2017'</span> : <span class="number">102</span>,</span><br><span class="line">    <span class="string">'static2011'</span> : <span class="number">1224</span>, </span><br><span class="line">    <span class="string">'kddcup2010'</span> : <span class="number">661</span>,  </span><br><span class="line">    <span class="string">'synthetic'</span> : <span class="number">50</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>模型超参数：主要包括所用数据集、输入输出维度、学习率、最大步长、学习周期等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">DATASET = datasets[<span class="string">'static2011'</span>]</span><br><span class="line">NUM_OF_QUESTIONS = numbers[<span class="string">'static2011'</span>]</span><br><span class="line"><span class="comment"># the max step of RNN model</span></span><br><span class="line">MAX_STEP = <span class="number">50</span></span><br><span class="line">BATCH_SIZE = <span class="number">64</span></span><br><span class="line">LR = <span class="number">0.002</span></span><br><span class="line">EPOCH = <span class="number">1000</span></span><br><span class="line"><span class="comment">#input dimension</span></span><br><span class="line">INPUT = NUM_OF_QUESTIONS * <span class="number">2</span></span><br><span class="line"><span class="comment"># embedding dimension</span></span><br><span class="line">EMBED = NUM_OF_QUESTIONS</span><br><span class="line"><span class="comment"># hidden layer dimension</span></span><br><span class="line">HIDDEN = <span class="number">200</span></span><br><span class="line"><span class="comment"># nums of hidden layers</span></span><br><span class="line">LAYERS = <span class="number">1</span></span><br><span class="line"><span class="comment"># output dimension</span></span><br><span class="line">OUTPUT = NUM_OF_QUESTIONS</span><br></pre></td></tr></table></figure>

<h4 id="模型实现-model"><a href="#模型实现-model" class="headerlink" title="模型实现-model"></a>模型实现-model</h4><p>模型在model目录下的RNNModel.py文件中实现，模型实际上就是一个简单的LSTM网络，其结构跟DKT原文中所讲述的结构一致，在LSTM模型最后添加了一个线性层和一个sigmoid激活函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DKT</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, hidden_dim, layer_dim, output_dim)</span>:</span></span><br><span class="line">        super(DKT, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.layer_dim = layer_dim</span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=<span class="literal">True</span>,nonlinearity=<span class="string">'tanh'</span>)</span><br><span class="line">        self.fc = nn.Linear(self.hidden_dim, self.output_dim)</span><br><span class="line">        self.sig = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        h0 = Variable(torch.zeros(self.layer_dim, x.size(<span class="number">0</span>), self.hidden_dim))</span><br><span class="line">        out,hn = self.rnn(x, h0)</span><br><span class="line">        res = self.sig(self.fc(out))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>

<h4 id="数据处理-data"><a href="#数据处理-data" class="headerlink" title="数据处理-data"></a>数据处理-data</h4><p>在data目录下包括三个文件：readdata.py、DKTDataSet.py、dataloader.py。它们的作用分别是定义数据的读取、pytorch框架下的数据集定义、以及pytorch框架下的dataloader的构造。</p>
<p><img src="http://img.chsong.live/Blogs/DKT-pytorch/6.png-o" alt=""></p>
<p><strong>readata</strong>: 在readata.py文件中，定义了一个类：DataReader，从名字可以看出这是一个用来读取数据的类。其中包含两个函数getTrainData()和getTestData()，分别是用来读取训练数据和测试数据。两个函数的定义其实一模一样，只是名字不一样用来区分训练和测试数据，这样的写法有些冗余，后面会再做一些优化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataReader</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, path, maxstep, numofques)</span>:</span></span><br><span class="line">        self.path = path</span><br><span class="line">        self.maxstep = maxstep</span><br><span class="line">        self.numofques = numofques</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTrainData</span><span class="params">(self)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTestData</span><span class="params">(self)</span>:</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>DataReader类有三个参数：</p>
<blockquote>
<p>path: 数据文件存储路径<br>maxstep: 最大序列长度<br>numofques: 此数据集中所有题目的总个数（去重后）</p>
</blockquote>
<p>获取与处理数据部分，以getTrainData()函数为例，getTestData()与其一样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTrainData</span><span class="params">(self)</span>:</span></span><br><span class="line">    trainqus = np.array([])</span><br><span class="line">    trainans = np.array([])</span><br><span class="line">    <span class="keyword">with</span> open(self.path, <span class="string">'r'</span>) <span class="keyword">as</span> train:</span><br><span class="line">        <span class="keyword">for</span> len, ques, ans <span class="keyword">in</span> tqdm.tqdm(itertools.zip_longest(*[train] * <span class="number">3</span>), desc=<span class="string">'loading train data:    '</span>, mininterval=<span class="number">2</span>):</span><br><span class="line">            len = int(len.strip().strip(<span class="string">','</span>))</span><br><span class="line">            ques = np.array(ques.strip().strip(<span class="string">','</span>).split(<span class="string">','</span>)).astype(np.int)</span><br><span class="line">            ans = np.array(ans.strip().strip(<span class="string">','</span>).split(<span class="string">','</span>)).astype(np.int)</span><br><span class="line">            mod = <span class="number">0</span> <span class="keyword">if</span> len%self.maxstep == <span class="number">0</span> <span class="keyword">else</span> (self.maxstep - len%self.maxstep)</span><br><span class="line">            zero = np.zeros(mod) - <span class="number">1</span></span><br><span class="line">            ques = np.append(ques, zero)</span><br><span class="line">            ans = np.append(ans, zero)</span><br><span class="line">            trainqus = np.append(trainqus, ques).astype(np.int)</span><br><span class="line">            trainans = np.append(trainans, ans).astype(np.int)</span><br><span class="line">    <span class="keyword">return</span> trainqus.reshape([<span class="number">-1</span>, self.maxstep]), trainans.reshape([<span class="number">-1</span>, self.maxstep])</span><br></pre></td></tr></table></figure>
<p>在getTrainData()中，首先定义两个numpy数组trainqus和trainans，前者存储题目编号，后者存储对应的答题结果。然后打开文件开始读取数据。</p>
<p>因为数据是三行格式的，所以每一次读取三行，每次读取三行的实现方式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> len, ques, ans <span class="keyword">in</span> tqdm.tqdm(itertools.zip_longest(*[train] * <span class="number">3</span>), desc=<span class="string">'loading train data:    '</span>, mininterval=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>其中tqdm是进度条展示，可忽略，简化来看每次读取三行的方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> len, ques, ans <span class="keyword">in</span> itertools.zip_longest(*[train] * <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>然后是对三行数据进行字符串处理，分别得到题目编号以及对应的答题结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ques = np.array(ques.strip().strip(<span class="string">','</span>).split(<span class="string">','</span>)).astype(np.int)</span><br><span class="line">ans = np.array(ans.strip().strip(<span class="string">','</span>).split(<span class="string">','</span>)).astype(np.int)</span><br></pre></td></tr></table></figure>
<p>然后是处理长度不一致的问题，将所有答题序列的长度都处理成maxstep的整数倍，长度不够的补0。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mod = <span class="number">0</span> <span class="keyword">if</span> len%self.maxstep == <span class="number">0</span> <span class="keyword">else</span> (self.maxstep - len%self.maxstep)</span><br><span class="line">zero = np.zeros(mod) - <span class="number">1</span></span><br><span class="line">ques = np.append(ques, zero)</span><br><span class="line">ans = np.append(ans, zero)</span><br></pre></td></tr></table></figure>
<p>举例：ques长度为18，设置maxstep为5，那么ques补充成maxstep的整数倍应该是4倍为20，所以ques应该补充两个0变成长度为20的序列；如果ques长度为11，那么补充4个0，长度变成15；ques长度为10，则不补充。</p>
<p>每一个ques的长度处理成maxstep的整数倍之后，添加到trainques数组中去，这样每一次添加都保证了trainques的长度为maxstep的整数倍。ans以及trainans的处理过程一样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainqus = np.append(trainqus, ques).astype(np.int)</span><br><span class="line">trainans = np.append(trainans, ans).astype(np.int)</span><br></pre></td></tr></table></figure>
<p>最后对trainques和trainans进行reshape，处理成N*maxstep的矩阵形式，N即可看做学生个数。maxstep即为答题个数。</p>
<p>举例，数据形式的变化过程，比如设置maxstep为3，总题目数为5，现在有如下三个学生的原始答题记录：<br>学生1：<br>2<br>1 2<br>1 0<br>学生2：<br>4<br>2 4 1 3<br>0 1 1 0<br>学生3：<br>7<br>5 3 1 4 5 4 2<br>0 0 1 1 0 1 0</p>
<p>ques通过readata读取并处理之后会变成：<br>1 2 0<br>2 4 1<br>3 0 0<br>5 3 1<br>4 5 4<br>2 0 0</p>
<p><strong>DKTDataSet</strong>：要定义pytorch框架下的数据集，需要继承torch的Dataset类，覆写__init__、__len__以及__getitem__三个函数。还可以根据需要自己添加数据处理的函数，在DKTDataSet中添加的one-hot处理函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DKTDataSet</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ques, ans)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onehot</span><span class="params">(self, questions, answers)</span>:</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>在readdata处理好数据之后，我们在DKTDataSet中对其进行封装处理，直接返回题目的one-hot形式而不再是题目编号。</p>
<p>在__init__中做一些初始化操作，比入读进数据ques和ans，前者是题目编号，后者是答题结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ques, ans)</span>:</span></span><br><span class="line">    self.ques = ques</span><br><span class="line">    self.ans = ans</span><br></pre></td></tr></table></figure>

<p>__len__返回数据集的长度（大小），这里直接返回ques或者ans的行数，也就是学生数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> len(self.ques)</span><br></pre></td></tr></table></figure>

<p>__getitem__返回需要获取的某条数据，这里根据index参数直接返回对应的数据即可，这里我们返回前将数据通过自定义的onehot函数处理成one-hot的形式，并且将数据类型转换为FloatTensor。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">    questions = self.ques[index]</span><br><span class="line">    answers = self.ans[index]</span><br><span class="line">    onehot = self.onehot(questions, answers)</span><br><span class="line">    <span class="keyword">return</span> torch.FloatTensor(onehot.tolist())</span><br></pre></td></tr></table></figure>

<p>__onehot__是自定义的将题目编号转变成one-hot形式的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">onehot</span><span class="params">(self, questions, answers)</span>:</span></span><br><span class="line">    result = np.zeros(shape=[C.MAX_STEP, <span class="number">2</span> * C.NUM_OF_QUESTIONS])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(C.MAX_STEP):</span><br><span class="line">        <span class="keyword">if</span> answers[i] &gt; <span class="number">0</span>:</span><br><span class="line">            result[i][questions[i]] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> answers[i] == <span class="number">0</span>:</span><br><span class="line">            result[i][questions[i] + C.NUM_OF_QUESTIONS] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>与原文保持一致，one-hot的维度为两倍的总题目数，所以对于readata中处理好的每一条记录ques，将变成[C.MAX_STEP, 2 * C.NUM_OF_QUESTIONS]大小的矩阵，因为每条记录ques中包含C.MAX_STEP个题目，每个题目的onehot维度为2 * C.NUM_OF_QUESTIONS。</p>
<p>接着readata中的例子，ques在DKTDataSet中转变成onehot形式之后，数据的形式变成：<br>[[1 0 0 0 0 0 0 0 0 0] -&gt; 1<br>&nbsp;[0 0 0 0 0 0 1 0 0 0] -&gt; 2<br>&nbsp;[0 0 0 0 0 0 0 0 0 0] -&gt; 0<br>&nbsp;[0 0 0 0 0 0 1 0 0 0] -&gt; 2<br>&nbsp;[0 0 0 1 0 0 0 0 0 0] -&gt; 4<br>&nbsp;[1 0 0 0 0 0 0 0 0 0] -&gt; 1<br>&nbsp;…]</p>
<p><strong>dataloader</strong>：在dataloader.py中，包含一个训练数据的loader和一个测试数据的loader，分别是getTrainLoader和getTestLoader，实际上这两个loader的实现一模一样，只是去了两个不同的名字为了区分训练和测试数据，这样的方式比较冗余，后面的版本会进行优化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTrainLoader</span><span class="params">(train_data_path)</span>:</span></span><br><span class="line">    handle = DataReader(train_data_path ,C.MAX_STEP, C.NUM_OF_QUESTIONS)</span><br><span class="line">    trainques, trainans = handle.getTrainData()</span><br><span class="line">    dtrain = DKTDataSet(trainques, trainans)</span><br><span class="line">    trainLoader = Data.DataLoader(dtrain, batch_size=C.BATCH_SIZE, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> trainLoader</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTestLoader</span><span class="params">(test_data_path)</span>:</span></span><br><span class="line">    handle = DataReader(test_data_path, C.MAX_STEP, C.NUM_OF_QUESTIONS)</span><br><span class="line">    testques, testans = handle.getTestData()</span><br><span class="line">    dtest = DKTDataSet(testques, testans)</span><br><span class="line">    testLoader = Data.DataLoader(dtest, batch_size=C.BATCH_SIZE, shuffle=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> testLoader</span><br></pre></td></tr></table></figure>
<p>关于如何定义loader就不做过多介绍，关于pytorch的dataloader的相关文章有很多。</p>
<p>在dataloader.py中还有一个函数：getLoader，这个函数封装了getTrainLoader和getTestLoader，通过调用此函数直接获取训练和测试的loader。并且函数的参数是数据集的名称，根据数据集名称分别为不同的数据集构造loader。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLoader</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    trainLoaders = []</span><br><span class="line">    testLoaders = []</span><br><span class="line">    <span class="keyword">if</span> dataset == <span class="string">'assist2009'</span>:</span><br><span class="line">        trainLoader = getTrainLoader(C.Dpath + <span class="string">'/assist2009/builder_train.csv'</span>)</span><br><span class="line">        trainLoaders.append(trainLoader)</span><br><span class="line">        testLoader = getTestLoader(C.Dpath + <span class="string">'/assist2009/builder_test.csv'</span>)</span><br><span class="line">        testLoaders.append(testLoader)</span><br><span class="line">    <span class="keyword">elif</span> dataset == <span class="string">'assist2015'</span>:</span><br><span class="line">        trainLoader = getTrainLoader(C.Dpath + <span class="string">'/assist2015/assist2015_train.txt'</span>)</span><br><span class="line">        trainLoaders.append(trainLoader)</span><br><span class="line">        testLoader = getTestLoader(C.Dpath + <span class="string">'/assist2015/assist2015_test.txt'</span>)</span><br><span class="line">        testLoaders.append(testLoader)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<h4 id="模型训练与测试-evaluation"><a href="#模型训练与测试-evaluation" class="headerlink" title="模型训练与测试-evaluation"></a>模型训练与测试-evaluation</h4><p>在evaluation目录下，有两个文件，一个是eval.py文件，主要实现模型的训练和测试以及品谷的过程；另一个是run.py文件，是主程序入口。</p>
<p><img src="http://img.chsong.live/Blogs/DKT-pytorch/7.png-o" alt=""></p>
<p><strong>eval</strong>：在eval.py文件中，定义了两个函数train和test分别实现模型的训练和测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(trainLoaders, model, optimizer, lossFunc)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(trainLoaders)):</span><br><span class="line">        model, optimizer = train_epoch(model, trainLoaders[i], optimizer, lossFunc)</span><br><span class="line">    <span class="keyword">return</span> model, optimizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(testLoaders, model)</span>:</span></span><br><span class="line">    ground_truth = torch.Tensor([])</span><br><span class="line">    prediction = torch.Tensor([])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testLoaders)):</span><br><span class="line">        pred_epoch, gold_epoch = test_epoch(model, testLoaders[i])</span><br><span class="line">        prediction = torch.cat([prediction, pred_epoch])</span><br><span class="line">        ground_truth = torch.cat([ground_truth, gold_epoch])</span><br><span class="line">    performance(ground_truth, prediction)</span><br></pre></td></tr></table></figure>
<p>而训练过程有分为很多epoch，每一个epoch的过程在train_epoch中实现。而对于测试过程，由于某些测试集可能会很大，导致内存一次存不下，所以将测试集分成多个loader，然后对于每一个loader都调用一次test_epoch，然后把所有的loader的结果合并起来。最后，所有的结果拼接起来后，通过performance函数计算模型的各个评价指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">    prediction = torch.cat([prediction, pred_epoch])</span><br><span class="line">    ground_truth = torch.cat([ground_truth, gold_epoch])</span><br><span class="line">performance(ground_truth, prediction)</span><br></pre></td></tr></table></figure>
<p>对于train_epoch，过程跟一般的pytorch模型训练过程一样，读取数据loader、预测、计算损失、反向传播等：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span><span class="params">(model, trainLoader, optimizer, loss_func)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm.tqdm(trainLoader, desc=<span class="string">'Training:    '</span>, mininterval=<span class="number">2</span>):</span><br><span class="line">        pred = model(batch)</span><br><span class="line">        loss = loss_func(pred, batch)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="keyword">return</span> model, optimizer</span><br></pre></td></tr></table></figure>
<p>对于test_epoch，由于知识追踪任务比较特殊，每一个时刻的输出都是预测下一个时刻答对题目的概率，因此有一些额外的处理。先上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_epoch</span><span class="params">(model, testLoader)</span>:</span></span><br><span class="line">    gold_epoch = torch.Tensor([])</span><br><span class="line">    pred_epoch = torch.Tensor([])</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm.tqdm(testLoader, desc=<span class="string">'Testing:    '</span>, mininterval=<span class="number">2</span>):</span><br><span class="line">        pred = model(batch)</span><br><span class="line">        <span class="keyword">for</span> student <span class="keyword">in</span> range(pred.shape[<span class="number">0</span>]):</span><br><span class="line">            temp_pred = torch.Tensor([])</span><br><span class="line">            temp_gold = torch.Tensor([])</span><br><span class="line">            delta = batch[student][:,<span class="number">0</span>:C.NUM_OF_QUESTIONS] + batch[student][:,C.NUM_OF_QUESTIONS:]</span><br><span class="line">            temp = pred[student][:C.MAX_STEP - <span class="number">1</span>].mm(delta[<span class="number">1</span>:].t())</span><br><span class="line">            index = torch.LongTensor([[i <span class="keyword">for</span> i <span class="keyword">in</span> range(C.MAX_STEP - <span class="number">1</span>)]])</span><br><span class="line">            p = temp.gather(<span class="number">0</span>, index)[<span class="number">0</span>]</span><br><span class="line">            a = (((batch[student][:, <span class="number">0</span>:C.NUM_OF_QUESTIONS] - batch[student][:, C.NUM_OF_QUESTIONS:]).sum(<span class="number">1</span>) + <span class="number">1</span>)//<span class="number">2</span>)[<span class="number">1</span>:]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(p)):</span><br><span class="line">                <span class="keyword">if</span> p[i] &gt; <span class="number">0</span>:</span><br><span class="line">                    temp_pred = torch.cat([temp_pred,p[i:i+<span class="number">1</span>]])</span><br><span class="line">                    temp_gold = torch.cat([temp_gold, a[i:i+<span class="number">1</span>]])</span><br><span class="line">            pred_epoch = torch.cat([pred_epoch, temp_pred])</span><br><span class="line">            gold_epoch = torch.cat([gold_epoch, temp_gold])</span><br><span class="line">    <span class="keyword">return</span> pred_epoch, gold_epoch</span><br></pre></td></tr></table></figure>
<p>在test_epoch函数中，先定义两个列表，分别用来存储真实结果ground truth 和预测的结果pred：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gold_epoch = torch.Tensor([])</span><br><span class="line">pred_epoch = torch.Tensor([])</span><br></pre></td></tr></table></figure>
<p>然后读取数据，分多个batch进行预测，因为一次预测可能数据量过大导致内存溢出而出错。Note：每一个batch中包含多个学生，每个学生有maxstep个题目，每个题目表示成了2*num_of_ques维的onehot向量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> tqdm.tqdm(testLoader, desc=<span class="string">'Testing:    '</span>, mininterval=<span class="number">2</span>):</span><br><span class="line">    pred = model(batch)</span><br></pre></td></tr></table></figure>
<p>预测完之后，整理数据，把学生所有的题目的预测结果存储起来，方便后面的评估。对于每一个学生，先创建两个列表，分别存储真是答题结果ground truth和预测结果pred。然后再将每个学生的结果添加进开始定义的两个总结果列表gold_epoch和pred_epoch中去。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> student <span class="keyword">in</span> range(pred.shape[<span class="number">0</span>]):</span><br><span class="line">    temp_pred = torch.Tensor([])</span><br><span class="line">    temp_gold = torch.Tensor([])</span><br></pre></td></tr></table></figure>
<p>然后是获取预测结果，这里先将2*num_of_ques维的题目onehot向量分成前后两个部分，每部分分别是num_of_ques维，然后相加，乘以预测结果，即可得到对应的题目的预测结果，这里的计算过程可自行推敲，等有机会再给出可视化的计算过程。因为每一个时刻都是预测的下一个时刻的结果，所以题目编号需要向后移一个，体现在delta[1:]这里：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">delta = batch[student][:,<span class="number">0</span>:C.NUM_OF_QUESTIONS] + batch[student][:,C.NUM_OF_QUESTIONS:]</span><br><span class="line">temp = pred[student][:C.MAX_STEP - <span class="number">1</span>].mm(delta[<span class="number">1</span>:].t())</span><br><span class="line">index = torch.LongTensor([[i <span class="keyword">for</span> i <span class="keyword">in</span> range(C.MAX_STEP - <span class="number">1</span>)]])</span><br><span class="line">p = temp.gather(<span class="number">0</span>, index)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>对于答题的真实结果，其实在onehot的向量中就已经体现了，答对则向量前半部分对应的位置为1，答错则向量后半部分对应的位置为1。根据这个特点，按照下面的方式就可以直接通过onehot向量推出真实答题结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = (((batch[student][:, <span class="number">0</span>:C.NUM_OF_QUESTIONS] - batch[student][:, C.NUM_OF_QUESTIONS:]).sum(<span class="number">1</span>) + <span class="number">1</span>)//<span class="number">2</span>)[<span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
<p>到此处为止，预测结果和真实结果就已经都得到了。但是，这里还要在做一个筛选，别忘了我们之前在数据长度不够的时候是补0了的，这里需要把补0的结果全部都过滤掉。由于补零的题目的onehot向量为全零向量，那么全零向量经过神经网络之后预测结果肯定为0。而正常题目不是非零的，那么预测结果为0的可能性极小，因为神经网络参数为0的可能性极小。所以我们根据预测结果是否为0，直接把为0的全部去除掉（我们这里的处理方法似乎不是很合理，因为正常题目也是有可能出现预测结果为0的情况，但是这种可能性极小，对模型整体而言几乎没什么影响，所以这么做也是合理的，并且十分方便）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> p[i] &gt; <span class="number">0</span>:</span><br><span class="line">    temp_pred = torch.cat([temp_pred,p[i:i+<span class="number">1</span>]])</span><br><span class="line">    temp_gold = torch.cat([temp_gold, a[i:i+<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<p>在每次处理完一个学生的数据之后，将其添加到总结果列表中去：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pred_epoch = torch.cat([pred_epoch, temp_pred])</span><br><span class="line">gold_epoch = torch.cat([gold_epoch, temp_gold])</span><br></pre></td></tr></table></figure>
<p>最后返回结果即可。</p>
<p>在eval.py文件中还定义了一个损失函数类lossFunc，基于pytorch框架的自定义的损失函数。其实这个损失函数就是分类问题中常用的交叉熵函数，只是知识追踪问题的数据是序列化的，所以这里不太方便直接调用pytorch框架中已有的交叉熵函数，自己按需实现了一下，里面涉及的一些过程和test_epoch中的部分过程类似：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">lossFunc</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(lossFunc, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, pred, batch)</span>:</span></span><br><span class="line">        loss = torch.Tensor([<span class="number">0.0</span>])</span><br><span class="line">        <span class="keyword">for</span> student <span class="keyword">in</span> range(pred.shape[<span class="number">0</span>]):</span><br><span class="line">            delta = batch[student][:,<span class="number">0</span>:C.NUM_OF_QUESTIONS] + batch[student][:,C.NUM_OF_QUESTIONS:]</span><br><span class="line">            temp = pred[student][:C.MAX_STEP - <span class="number">1</span>].mm(delta[<span class="number">1</span>:].t())</span><br><span class="line">            index = torch.LongTensor([[i <span class="keyword">for</span> i <span class="keyword">in</span> range(C.MAX_STEP - <span class="number">1</span>)]])</span><br><span class="line">            p = temp.gather(<span class="number">0</span>, index)[<span class="number">0</span>]</span><br><span class="line">            a = (((batch[student][:, <span class="number">0</span>:C.NUM_OF_QUESTIONS] - batch[student][:, C.NUM_OF_QUESTIONS:]).sum(<span class="number">1</span>) + <span class="number">1</span>)//<span class="number">2</span>)[<span class="number">1</span>:]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(p)):</span><br><span class="line">                <span class="keyword">if</span> p[i] &gt; <span class="number">0</span>:</span><br><span class="line">                    loss = loss - (a[i]*torch.log(p[i]) + (<span class="number">1</span>-a[i])*torch.log(<span class="number">1</span>-p[i]))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<p>最后，eval.py文件中包含一个performance函数，从名字就可以看出这个函数用来评价模型的表现，也就是计算预测结果的各个指标，包括AUC、F1、Recall、Precision，可以根据需要自行添加，计算方式可自定义或者直接掉包：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">performance</span><span class="params">(ground_truth, prediction)</span>:</span></span><br><span class="line">    fpr, tpr, thresholds = metrics.roc_curve(ground_truth.detach().numpy(), prediction.detach().numpy())</span><br><span class="line">    auc = metrics.auc(fpr, tpr)</span><br><span class="line">    f1 = metrics.f1_score(ground_truth.detach().numpy(), torch.round(prediction).detach().numpy())</span><br><span class="line">    recall = metrics.recall_score(ground_truth.detach().numpy(), torch.round(prediction).detach().numpy())</span><br><span class="line">    precision = metrics.precision_score(ground_truth.detach().numpy(), torch.round(prediction).detach().numpy())</span><br><span class="line">    print(<span class="string">'auc:'</span> + str(auc) + <span class="string">' f1: '</span> + str(f1) + <span class="string">' recall: '</span> + str(recall) + <span class="string">' precision: '</span> + str(precision) + <span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<p>到此处为止，DKT项目的所有部分都已介绍完毕。由于时间仓促，并没有把所有细节都介绍很清楚，但对于学习和理解DKT来说已经足够了。后续有时间会根据需要补充一些更细节的介绍，如果有什么问题或建议可直接评论留言，我会及时回复，或者通过主页的邮箱联系。</p>

<font color=red>这里有一个知识追踪前沿研究技术交流群，即日起，群二维码过期不再更新，进群可通过扫码关注公众号在互动专区加群。
</font>


<p><img src="https://img.chsong.live/Blogs/DKT-pytorch/DKT%E4%BA%A4%E6%B5%81%E7%BE%A4.png-m" alt=""></p>
<p><img src="http://img.chsong.live/Blogs/guanzhu.png-o" alt=""><br><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>

	  


      	  

      
      <!-- 打赏 -->
      
        <div id="reward-btn">
          ~赞~
        </div>
        
    </div>

  </div>

  
  
  <nav class="article-nav">
    
      <a href="/20201205_%E5%8F%98%E9%95%BF%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            变长循环神经网络 [Pytorch]
          
        </div>
      </a>
    
    
      <a href="/20201123_%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/index.html" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">游戏实时胜率预测</div>
      </a>
    
  </nav>


  

  
  
    <table style="width:900px; height: 280;">
        <tr style="width:900px; height: 280;">
          <td style="height: 280px; width: 300px;">
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7950001743265524"
     crossorigin="anonymous"></script>
<!-- gAD04 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7950001743265524"
     data-ad-slot="8472534508"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
          </td>
          <td style="height: 280px; width: 300px;">
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7950001743265524"
            crossorigin="anonymous"></script>
       <!-- gAD04 -->
       <ins class="adsbygoogle"
            style="display:block"
            data-ad-client="ca-pub-7950001743265524"
            data-ad-slot="8472534508"
            data-ad-format="auto"
            data-full-width-responsive="true"></ins>
       <script>
            (adsbygoogle = window.adsbygoogle || []).push({});
       </script>
          </td>
          <td style="height: 280px; width: 300px;">
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7950001743265524"
            crossorigin="anonymous"></script>
       <!-- gAD04 -->
       <ins class="adsbygoogle"
            style="display:block"
            data-ad-client="ca-pub-7950001743265524"
            data-ad-slot="8472534508"
            data-ad-format="auto"
            data-full-width-responsive="true"></ins>
       <script>
            (adsbygoogle = window.adsbygoogle || []).push({});
       </script>
          </td>
        </tr>
      </table>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7950001743265524"
    crossorigin="anonymous"></script>
<!-- gAD01 -->
<ins class="adsbygoogle"
    style="display:block"
    data-ad-client="ca-pub-7950001743265524"
    data-ad-slot="3571453818"
    data-ad-format="auto"
    data-full-width-responsive="true"></ins>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({});
</script>

    <!-- valine评论 -->
<div id="vcomments-box">
    <div id="vcomments">
    </div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>
<script>

    var GUEST_INFO = ['nick','mail','link'];
    var guest_info = 'nick,mail,link'.split(',').filter(function(item){
        return GUEST_INFO.indexOf(item) > -1
    });
    guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

    new Valine({
        el: '#vcomments',
        notify: false,
        verify: false,
        app_id: 'IBXbYeb2rqEJjd9E7AbMgdey-gzGzoHsz',
        app_key: 'RLhFH89nQaSMGKs0Nl2egMtM',
        path: window.location.pathname,
        avatar: 'wavatar',
        placeholder: '~取个昵称吧，方便大家区分~',
        recordIP: true,
        meta: guest_info,
        requiredFields: ['nick', 'mail']
    });
    const infoEle = document.querySelector('#vcomments .info');
    if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
        infoEle.childNodes.forEach(function (item) {
            item.parentNode.removeChild(item);
        });
    }
</script>
<style>
    #vcomments-box {
        padding: 5px 30px;
    }

    @media screen and (max-width: 800px) {
        #vcomments-box {
            padding: 5px 0px;
        }
    }

    #vcomments-box #vcomments {
        background-color: #fff;
    }

    .v .vlist .vcard .vh {
        padding-right: 20px;
    }

    .v .vlist .vcard {
        padding-left: 10px;
    }
</style>

  

  
  
  
  

</article>
</section>
      <footer class="footer">
	<div class="outer">
		  	  <!-- 版权 -->
		  	  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
		      <div align="center">
			        &copy;
			        2019-2021
			        <font color="grey" size="3px">&hearts;</font>
			        Cheng Song

		      &nbsp;

					<!-- 备案 -->
				    <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow"><img src="https://img.chsong.live/Background/images/beian.png?x-oss-process=style/o" height="18px" weight="18px" align="center"/>鄂ICP备20012823号</a>
		      </div>
	</div>

	<div align="center">
	<div class="powered-by">
		<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
		  本站访客数: <span id="busuanzi_value_site_uv"></span>
		</span>
	&nbsp; 	
		<i class="fa fa-user-md"></i><span id="busuanzi_container_page_pv">
			本文阅读量: <span id="busuanzi_value_page_pv"></span>
		</span>

	</div>
	</div>
</footer>
    <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
    
    <aside class="sidebar">
      
        <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
      <a href="/index.html"><img class="rotate" src="https://img.chsong.live/Background/images/cs.svg" alt=""></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives/index.html">时间轴</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/index.html">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/gallery/index.html">相册</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/shuoshuo/index.html">动态</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about/index.html">主页</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>

    <li class="nav-item">
      <a class="nav-item-link" href="https://github.com/chsong513/" target="_blank" rel="noopener">
        <img src="https://img.chsong.live/Background/images/github.png?x-oss-process=style/o" style="weight:25px; height:25px;"/>
      </a>
    </li>

<!--     <li class="nav-item">
      <a class="nav-item-link" href="mailto:chsong@mail.ustc.edu.cn">
        <img src="https://img.chsong.live/Background/images/mail.png?x-oss-process=style/o" style="weight:19.2px; height:15px;"/>
      </a>
    </li> -->

  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
      </aside>
      <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>么么哒，请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://img.chsong.live/Background/images/alipay.jpg?x-oss-process=style/o">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://img.chsong.live/Background/images/wechat.png?x-oss-process=style/o">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
      
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>


  
<script src="/fancybox/jquery.fancybox.min.js"></script>




  
<script src="/js/tocbot.min.js"></script>

  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>


<script>
  var ayerConfig = {
    mathjax: false
  }
</script>


<script src="/js/ayer.js"></script>


<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">



<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>
  
  
  </div>
</body>

</html>