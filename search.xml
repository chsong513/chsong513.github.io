<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>你不能比我好</title>
    <url>/20210420_%E4%BD%A0%E4%B8%8D%E8%83%BD%E6%AF%94%E6%88%91%E5%A5%BD/index.html</url>
    <content><![CDATA[<p><img src="https://img.chsong.live/Blogs/%E4%BD%A0%E4%B8%8D%E8%83%BD%E6%AF%94%E6%88%91%E5%A5%BD/6.jpeg-o" alt=""></p>

<h3 align="center">
你正在经历的情绪型嫉妒
</h3>

<p>当你看到有人在奥运会上得了冠军，他上台领奖的时候，你应该会替他感到高兴。你会因为领奖的人不是你而感到难过甚至气愤吗，应该不会吧。可当你工作了一整天，回家却发现TA在悠闲的追着剧，或者你的孩子在槑头槑脑的玩耍，你的心里有时可能会怒火中烧。你自己也感到奇怪，你看到TA和小孩不应该很高兴吗，你工作不也是为了多挣钱让你们过得更好吗，为什么有时候看到TA们那么悠闲时会很愤怒呢？这个时候，你所经历的是一种情绪型嫉妒。这种情绪捉摸不定，也很难说出个所以然，可它确实真实存在的，并且很多人都会受到这种困扰。</p>
<a id="more"></a>

<h3 align="center">
你的情绪是有比较产生的
</h3>

<p>情绪型嫉妒中包括两个观念，第一个观念是人的情绪是比较而来的。当你一个人在发呆的时候，情绪不太会有很大的起伏。而当你跟其他人共处的时候，可能经常会说：“我看见那人就来气，只要一看见就不舒服”。可这些气从哪来呢？这是因为你通过比较产生了j情绪，当你跟其他人共处的时候，情绪是会受到感染的。</p>
<p>这种感染有的时候是顺着对方的方向。比方说看电影，如果是喜剧，有人笑出来我们就跟着笑；如果是恐怖片，有人尖叫我们也跟着害怕。这就是为什么当你一个人在家里面看电视的时候，会发现电视节目经常营造出你跟其他人共处的感觉。比如看一些喜剧小品，节目会配上罐头笑声，那些罐头笑声明明不是跟你共处的，可是你还是会受到感染而笑出来；一些唱歌节目，喜欢特写观众席当中一些人听了歌而泪流满面的表情，节目希望借由这样的情绪感染来打动在家一个人看电视的你。这类情绪感染是要把你拉往同一个方向。</p>
<p>这种感染有的时候是逆着对方的方向。在情人节，别的情侣都在甜蜜的时候，为什么单身的人会说自己是狗呢？因为亲眼目睹别人穿情侣装、吃情侣套餐、买玫瑰花，就会感觉自己一个人形单影只，因为比较产生的情绪温差，情绪的感染就把你推向了相反的方向。</p>

<h3 align="center">
当你与比较的对象相关
</h3>

<p>比较产生情绪，这个时候其实远远不足以让你生气甚至愤怒。而你生气或者愤怒的时候，是因为受到了情绪型嫉妒第二个观念的影响，那就是你觉得嫉妒的对象是你自己可以与其相比的对象。奥运会冠军对一般人来说可能是永远滴神，大家根本不觉得要跟他比较；看娱乐新闻的时候，一个男明星娶了你最喜欢的女明星，你会很羡慕，你也会跟朋友调侃一下：“好白菜都让猪拱了”，但绝不会寝食难安。可是如果在公司里面，你最喜欢的一个女同事跟你最讨厌的一个男同事在一起了，这个时候你就会感受到情绪型嫉妒，因为他是你认为可以比较的且跟你相关的对象。</p>
<p>再比如，你就是一个普通的上班族，而有一天新闻上说某个小孩很聪明很优秀、某个年轻的博士当选了教授、某人开了个烧烤店年入百万，看到这些你最多是羡慕一下。可如果这些人都是你的大学同学，年末的时候说开个同学聚会，你会很开心很从容很享受的去吗？你很容易陷入强烈的情绪型嫉妒，因为你知道在某一个程度上，你们曾经是属于同一个族群的人。</p>
<p>当你辛苦工作了一整天，回到家的时候，看到你养的小狗正在跳来跳去，你会觉得很温暖很安慰。可如果看到的是小孩在跳来跳去，你可能会立刻很生气。会立刻说：“你功课都做好了吗？还没做好功课为什么在玩？赶快回房间好好学习”。小狗是你养的宠物，你不会期待它跟你一样的辛苦；而家人你觉得是应该同甘共苦的，你在外面工作很累，回到家就希望家里的气氛跟你的累是相称的一致的，所以你希望小孩也因为作业很多而加油，希望TA也因为家务活儿多而忙碌。</p>

<h3 align="center">
关注自己多一点
</h3>

<p>通过比较让你产生了情绪，而你比较的对象让你感到了失望，于是产生了愤怒的情绪型嫉妒。情绪型嫉妒如果偶尔发生也无关紧要，可如果经常出现，那就说明你在潜意识里把很多人都列入了比较名单跟你进行对比，比如一起生活的家人、过去的老同学、公司的同事等，这样你就会一次又一次的受到情绪型嫉妒的困扰，很累而且没意义。关注自己，跟自己比较，每天进步一点点，你会发现家庭氛围更好了、同学关系更铁了、同事相处更融洽了。</p>

</br>
</br>
</br>
<h4 align="center">
-END-
</h4>
</br>
</br>
</br>


<p>【<a href="https://mp.weixin.qq.com/s?__biz=Mzg3MDIwMTgzNQ==&mid=2247484186&idx=1&sn=3786c68eb3cecf1dacd782a88c4d5f65&chksm=ce90239ef9e7aa8821d2e0c44ad5c1ddab65fef4262be049cd21c16a55bf5993b5549b0cdf24&token=1886932722&lang=zh_CN#rd" target="_blank" rel="noopener">阅读原文</a>】<strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>一切皆可解读</tag>
      </tags>
  </entry>
  <entry>
    <title>婆娑境里的流浪</title>
    <url>/20210419_%E5%A9%86%E5%A8%91%E5%A2%83%E9%87%8C%E7%9A%84%E6%B5%81%E6%B5%AA/index.html</url>
    <content><![CDATA[<p><img src="http://img.chsong.live/Blogs/%E5%A9%86%E5%A8%91%E5%A2%83%E9%87%8C%E7%9A%84%E6%B5%81%E6%B5%AA/1.png-o" alt=""></p>
<a id="more"></a>
<p><img src="http://img.chsong.live/Blogs/%E5%A9%86%E5%A8%91%E5%A2%83%E9%87%8C%E7%9A%84%E6%B5%81%E6%B5%AA/2.png-o" alt=""></p>
<p>【<a href="https://mp.weixin.qq.com/s?__biz=Mzg3MDIwMTgzNQ==&mid=2247484165&idx=1&sn=0ef51fea1f7058a7936578831c77a1a2&chksm=ce902381f9e7aa9744d63ca720dd86a76cb3fd5c91af25686a60d893dc5a096316633627fea7&token=1886932722&lang=zh_CN#rd" target="_blank" rel="noopener">阅读原文</a>】<strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
]]></content>
      <tags>
        <tag>一切皆可解读</tag>
      </tags>
  </entry>
  <entry>
    <title>你还会“袖手旁观”吗？</title>
    <url>/20210416_%E4%BD%A0%E8%BF%98%E6%95%A2%E8%A2%96%E6%89%8B%E6%97%81%E8%A7%82%E5%90%97/index.html</url>
    <content><![CDATA[<p><img src="https://img.chsong.live/Blogs/%E4%BD%A0%E8%BF%98%E4%BC%9A%E8%A2%96%E6%89%8B%E6%97%81%E8%A7%82%E5%90%97/1.jpeg-o" alt=""></p>
<p>旁观最可恨，你还会“袖手旁观”吗？</p>
<a id="more"></a>


<h3 align="center">
芳华
</h3>

<p>最近，重看了一部电影芳华，可以说是冯小刚导演这些年来比较成功的一部作品。记得当时上映不到半个月的时间，势头不减，电影院里甚至还有很多中老年人。它这么吸引人的原因是什么呢，应该是电影里面的人物以及情怀感动了很多人，更重要的应该是大家能从这个作品中的人物身上看到自己的影子。</p>

<h3 align="center">
可怜
</h3>

<p>电影芳华里面，有两个可怜的人物，一个是被大家孤立的何小萍，一个是烂好人刘峰。这两种人在我们生活当中都是少数人，并不多见。所以很多人能从旁观者中立的角度看待这两个人，说何小萍很可怜，而且刘峰却不受大伙儿待见，很多人就觉得难受。但其实如果我们有代入感的话，芳华这电影里有我们自己的影子。这个人就是萧穗子，这部电影就是以萧穗子的角度去讲述的，她其实就是这部电影的编剧兼小说原作者严歌苓的化身。电影说的就是她当年在文工团时候的事儿，这里的萧穗子其实就是严歌苓在这个生活中的样子。对于自己这个作品，芳华严歌苓说过这样一句话：“我有自己的一份忏悔。因为当年欺负战友的经历，也有我的一份罪恶。写这个故事也在幻想我当年的角色给出一份忏悔，给出一份批判”。这话是什么意思呢？可以看到，电影中的何小萍和刘峰，他们都是被同情的，大家同情的是他们被欺负的遭遇，也更加同情刘峰这样的烂好人没有得到应有的回报。那么这种事情是谁造成的呢？大家都说你看电影里面很多欺负人的，什么小芭蕾呀，还有谁谁谁呀，包括林丁丁怎么怎么样，但很少有人想到萧穗子，她的一些行为方式也是造成何小萍和刘峰悲剧命运的一个重要推手。</p>

<h3 align="center">
旁观
</h3>

<p>为什么这么说呢？有人说萧穗子就是个旁观者呀，她也没有直接害谁啊，大多数时候人家都是保持中立的。而实际上，旁观者中立者是要有担当的，作为一个中立者，也不是一件简单的事情，中立旁观绝对不是袖手旁观。这样的角色，也是要有一定情商的含量。萧穗子在影片中戏份不多，零零散散的出现，可是留给观众的印象很深。因为作为叙述者的身份，视角和观众比较接近。比如偷军装事件当中，其他人都指责何小萍偷拿服装拍照，但是萧穗子没有落井下石。后来的内衣海绵事件，其他人都围堵刁难何小萍，萧穗子也没有参加批评。大家非常气愤何小萍被人欺负，活雷锋刘峰被诬陷，作为影片的观看者，我们无法参与影响电影里面发生的事情，影响电影里面主角的命运，所以再怎么气氛也没用。可萧穗子不一样，她是这些事件的直接参与者，她是能够在其他人指责何小萍的时候帮忙说话缓和气氛的；她也可以在小芭蕾强行撕扯何小小萍时出来制止的；她也可以出面为刘峰澄清事实真相的。可是这个旁观者萧穗子最后什么都没做，包括何小萍被质问的时候，她就在门口看着何小萍差点被扯掉身上的衣服，一直等到女教官出来阻止之后，她才来个事后诸葛亮，只是简单说了一句：“你这样做有点过分”。看着刘峰被下放，她也没有说一句话，她所有这些选择都是出于一个原因，因为她认为这个中立态度谁也不得罪，这是她在文工团的立足之本。芳华里的文工团这些人其实跟平常在公司或单位里是一样的，大家都要在这个团体当中，找到自己安身立命的方式。</p>
<p>郝淑雯有一个在部队里做高层领导的父亲，说话做事为所欲为，不怕得罪人。林丁丁有着让人神魂颠倒的姿色，很多男性被他迷得神魂颠倒，从来不缺乏追求者。刘峰什么都会，不管什么事情，他都能帮得上忙。这些人都有能在文工团安身立命的方式和方法。可是萧穗子没什么特点，前面这几个人有的东西她都没有，要想在这个团体生存下去，唯一的办法就是保持中立，不得罪人。其实这是个挺好的办法，可是问题在于她在中立者的道路上跑偏了，把自己从中立者变成了一个旁观者，也就是袖手旁观，不管发生什么事情，不管谁对谁错，都是一个看客，置身事外。她变成了一个典型的不参与的看热闹的看客。所以当发生事情之后，首先想到的是把自己给保护好了，别得罪人。这样的做法表面上看，它只是保护了自己，也没去伤害别人，也挑不出她什么错。可是这种旁观者的行为客观上推动了被伤害的那个人的遭遇向极端方向加速。当施害人、被害人和旁观者这三种人并存的时候，事情往往都会朝着恶性方向发展。因为作为旁观者看到事情不管，其实就等于在纵容这种迫害行为，甚至会助长施害者的气焰，让他们做事情越来越无所顾忌。</p>

<h3 align="center">
纵容
</h3>

<p>二战期间，有个叫马丁尼莫拉的牧师，他写过这样一段很有名的文字，“起初法西斯追杀共产主义者，我没有说话，因为我不是共产主义者；接着他们追杀犹太人的时候，我也没说话，因为我不是犹太人；后来他们追杀公会成员的时候，我没有说话，因为我不是工会成员；此后他们追杀天主教徒的时候，我也没说话，因为我是新教教徒，不是天主教教徒；最后他们奔我而来了，结果没人替我说话了”。所以，这就是当别人受难的时候，我们只顾自己觉得跟自己没关系，可别惹祸上身，等轮到自己的时候后悔都来不及。</p>
<p>战国时期的一个很好的例子，当时秦国的实力越来越强，秦国的国君一直有吞并其他国家一统天下的想法。其他国家的实力相对比较弱，任何一个都没法跟秦国抗衡，可如果这6个国家联合到一起，在一定程度就能遏制秦国，秦国就不敢轻举妄动。所以秦国尽管实力远胜于其他国家，但一直没有实际的行动，没有主动攻打这些国家，因为他害怕一旦攻打，这6个国家联合起来对付自己，那可就糟了。但总这么耗着也不是事儿，秦国就忍不住开始试探我先打一架试试他们反应。结果这一试，秦国高兴坏了，这些国家各怀心思，并不像他设想的那样几个国家合起来对付秦国，而是一个个都怕得罪秦国，怕给自己招来灾祸，结果都选择袖手旁观，也不出兵增援。秦国心想我占别人地方你们不管，那灭别人的国家看你们管不管，结果秦国开始灭国还是没人管。这么多的旁观者而袖手旁观，逍遥事外，让秦国唯一的顾虑都打消了，肆无忌惮开展吞没行动，最后统一中国。一开始秦国有这样的能力和想法，但他不敢这么做。但他尝试打了一仗之后，发现别的国家都是旁观者没人管，因此秦国就可以得寸进尺。最后能成功，其实是就得益于旁观者的这种沉默，所以说灭六国者，六国也，非秦也。六国一个个全让秦国灭了，相比灭掉他们的秦国外，这些有能力但却选择袖手旁观的人更可恨。</p>
<p>再回头来看芳华，在何小萍决定装病放弃演出的时候，萧穗子说了一句话，她说在很多年之后才明白为什么何小萍当时会做出那样的决定。因为那个时候何小萍看到刘峰遇到困难被人针对的时候，没有人站出来说一句公道话，都选择去做助长施害人气焰的旁观者，何小平为这件事来气，所以才决定放弃舞蹈演出。那么萧穗子后来认清楚了，这是由于她自认为旁观者就是中立者的态度，客观上推动了刘峰冤案的发展。后来萧穗子成熟以后，她要反省，这其实也代表着作者严歌苓对当年所作所为的一种忏悔。中立不是旁观，真正的中立，是能够独立于任何一方之外的一种立场，拥有自己的主见，掌握事实的真相，不去偏向任何一方，并不是说我中立这个事就跟我没有关系。中立不是不管，而是带着一种公正的立场去管，而且前提是得有能力管，管的还得是对的。</p>

<h3 align="center">
中立
</h3>

<p>真正的中立最典型的是三国吕布辕门射戟。每次提到吕布这个人物的时候，大家对他的印象基本都是负面的，有勇无谋，反复无常，见利忘义，张飞给他起了个外号叫三姓家奴。但即使是这样的人，他也有非常出彩的一面，就是辕门射戟，吕布就做了一个非常成功的中立者。当时袁术准备发兵打刘备，而刘备这时候在小沛住着，吕布占据着徐州，刘备这时候跟吕布达成联盟。袁术势力大而刘备势力单薄，要想打刘备，很容易就能拿下。刘备也知道这个问题，所以他只能向在徐州的吕布求援，他跟吕布讲利害关系，说你看小沛挨着徐州，我在这等于替你挡住袁术，你也知道袁术贼心不死，要是我被灭了，唇亡齿寒，你也干不过袁术，下一个就轮到你，所以咱们是拴一个绳子的蚂蚱，你得帮我。刘备这种想法，袁术肯定也能猜到，心想一旦刘备跟吕布合伙起来，这计划得泡汤。所以袁术也派人去游说吕布，说我们向你承诺，我们只打刘备，绝对不会侵犯到您吕将军，为表示我们的诚意，说我愿意送你两年的军粮。那个时候这军粮可比啥都重要，没有粮食，军队怎么打仗，所以这两年的军粮，解决了吕布的粮食问题，这对他太有诱惑力。一边是唇亡齿寒的利害关系，一边又有军粮的诱惑，不管他帮哪边，对他来说都是损失，帮刘备没粮食，帮袁术自己最后可能就得吃亏，到底怎么选择呢？</p>
<p>吕布纠结半天，最后决定了谁都不帮，结果谋士陈宫一听这个决定气坏了，他说你这谁都不帮，人家刘备跟袁术都会认为你要趁着双方大战坐收渔翁之利，你这不两边都得罪了吗？吕布告诉陈宫说陈先生你放心，我说的不帮是让两家罢手言和，而不是啥都不干。吕布在双方要开始交兵的时候，吕布就在五里坡摆下酒宴，把刘备和袁术以及大将纪灵都给请来了，两边人碰到一块就要打，吕布说，别别别，在我这地方怎么也得给我个面子，我让你们来呀，可不是看你们动手打架的。等坐下来之后，袁术手底下大将纪灵说我们跟你都说好了，你这干嘛出来碍手碍脚的，就问吕布说将军来可是为了杀我的？吕布说不是。纪灵说那你不是杀我，你就要杀对面的大耳贼刘备。吕布说也不杀他，我也不傻，我谁都不杀，你看我这人好勇斗狠，但我还喜欢给别人说和。吕布说你们几位都听我说，你张飞还有纪灵，您二位能拉开多少斤的弓，能射多远？纪灵说我能射五十步，张飞说我六十步。吕布说这么着，把我这个方天画戟插在辕门的地方，你俩也别争，从这里到辕门有一百二十步，你们能射这么远吗？这俩人不吱声了。吕布接着说，那好，我今天跟你们打个赌，我就在这里射出一箭，能射到120步开外的方天画戟，我要是射不中，我不管你们，你们打不打跟我没关系，我要射中了，你们双方要罢兵休战，各回各家，各找各妈。纪灵就琢磨了，这不扯吗？那吕布根本射不中啊。刘备这边琢磨，你可千万要射中啊，你要射不中，我就被灭了。这吕布也是真有能耐，120步开外，正中方天画戟。这下袁术手底下大将纪灵没办法了，只好选择撤退。</p>
<p>吕布做到了真正的中立，他独立于刘备和袁术之外，不受他们请求的干扰，不偏不笑，他利用自己的优势，让双方接受了罢斗撤兵的结果，自己把刘备这人情收了，也把袁术这粮草收了。所以三国里面有首诗写得好：“一箭能销两造兵，温侯也善解纷争。辕门射戟传佳话，如听当年嚆矢声”。</p>
<p>真正的中立，看上去简单，但真要做起来难度不小。你的态度不公正不行，你的能力不够不行，参与者对你不认同也不行，方方面面都得顾及到，稍微有一点偏差就容易出问题，不光解决不了纷争，还会把自己弄得里外不是人。即便是这些问题都能做到，但只要保持中立，那必然会让夹在中间左右为难。有时候并不是说做好就一定被人理解，这里也需要很强的承受能力，甚至是承担风险。</p>

<h3 align="center">
结束
</h3>

<p>芳华中的萧穗子在很多时候是有能力解决何小萍和刘峰的问题的，但是她为什么不解决，除了自己要安身立命以外，还有一点，就是出面解决一些问题总会使自己承受压力，有风险。萧穗子心里承受能力比较弱，做一个中立者，虽然看着自私，但是也情有可原。所以严歌苓多年之后的这种忏悔是他发自内心的。</p>
<p>所以，遇到一些事情，如果没有那么大的伤害度，不会承担太大风险的时候，最好不要做一个旁观者，要对这个事情给予干预，尤其是涉及到公平正义的时候，不能眼睁睁看着弱者被一些强者去欺负。否则的话，这些强者有一天也会把手伸到我们这里，我们也会成为那个弱者。不仅个人要如此，当今国际形势其实也是如此，比如抗美援朝就是很好的例子。</p>
<p>中立有风险，入坑需谨慎！</p>

</br>
</br>
</br>
<h4 align="center">
-END-
</h4>
</br>
</br>
</br>


<p>【<a href="https://mp.weixin.qq.com/s?__biz=Mzg3MDIwMTgzNQ==&mid=2247483940&idx=1&sn=e2bb80c06cce0933181cb694a5920059&chksm=ce9022a0f9e7abb688eb01109459197f7c204d51a3a3ae851bad34d54847e3b6dae434e42728&token=1886932722&lang=zh_CN#rd" target="_blank" rel="noopener">阅读原文</a>】<strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>一切皆可解读</tag>
      </tags>
  </entry>
  <entry>
    <title>五杀片段</title>
    <url>/20201229_%E4%BA%94%E8%BF%9E%E7%BB%9D%E4%B8%96/index.html</url>
    <content><![CDATA[<p>首次五杀，居然是之前一直不怎么喜欢的大小姐。</p>
<p><img src="http://img.chsong.live/Blogs/%E4%BA%94%E8%BF%9E%E7%BB%9D%E4%B8%96/%E5%AD%99%E5%B0%9A%E9%A6%99.jpg-o" alt="五杀"></p>
<a id="more"></a>

<p><video src="http://chengsong-img.oss-cn-hangzhou.aliyuncs.com/Blogs/%E4%BA%94%E8%BF%9E%E7%BB%9D%E4%B8%96/%E5%AD%99%E5%B0%9A%E9%A6%99.mp4" width="800px" height="450px" controls="controls"></video> </p>
<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>动态</tag>
      </tags>
  </entry>
  <entry>
    <title>PCA与SVD之间的关系</title>
    <url>/20201205_PCA%E4%B8%8ESVD%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/index.html</url>
    <content><![CDATA[<p><img src="http://img.chsong.live/Blogs/PCA%E4%B8%8ESVD%E7%9A%84%E5%85%B3%E7%B3%BB/1.png-m" alt="PCA"></p>
<p>在用数据对模型进行训练时，通常会遇到维度过高，也就是数据的特征太多的问题，有时特征之间还存在一定的相关性，这时如果还使用原数据训练模型，模型的精度会大大下降，因此要降低数据的维度，同时新数据的特征之间还要保持线性无关。有一种方法称为主成分分析（Principal component analysis，PCA），新数据的特征称为主成分，得到主成分的方法有两种：直接对协方差矩阵进行特征值分解和对数据矩阵进行奇异值分解（SVD）。</p>
<a id="more"></a>

<h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><p>一种经典的数据降维算法，推导过程有多种形式：最近重构性、最大可区分性等。这里以最大可区分性为例。</p>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>设$X\in R^{n\times d} = {x_1, x_2,\dots, x_n}$为数据集，包含$n$个样本，每个样本有$d$维特征, 即$x_i\in R^{d}$。</p>
<h3 id="降维可视化"><a href="#降维可视化" class="headerlink" title="降维可视化"></a>降维可视化</h3><p><img src="http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/1095279401413/1576909454842_sVWwhScNGQ.jpg" alt=""></p>
<p>降维的目的，是为了找到一个映射矩阵$W\in R^{k\times d}$,将原始数据都映射到d维空间中。</p>
<p>如图所示，以2维空间到1维空间降维为例。原数据在直线上的映射点的位置之与直线的斜率（或者说是方向向量）有关，且直线是可以平移的。因此我们假设目标直线是过原点的，即：$Wx = 0$。</p>
<h3 id="W求解过程"><a href="#W求解过程" class="headerlink" title="W求解过程"></a>W求解过程</h3><p>每一个数据点$x_i$映射到直线$Wx=0$上之后，映射点为：$Wx_i$</p>
<p>那么数据集$X$映射后的数据为:$XW^T\in R^{n\times k}$</p>
<p>step1: 映射矩阵$W\in R^{k\times d}$将数据集$X$映射到$k$维空间：$XW^{T}$</p>
<p>step2: 映射后，数据的协方差矩阵为：$(XW^{T})^{T}(XW^{T})=WX^{T}XW^{T}$</p>
<p>最大可区分性，就是使得数据在各个维度上的方差最大，也就是数据最分散，越分散区分性越大。因此最大可区分性的优化目标就是，数据集在各位维度上的方差最大化。而各个维度的方差等于协方差矩阵的对角元素之和，也就是矩阵的迹。</p>
<p>step3: 因此优化目标：$min \text{tr}(WX^{T}XW^{T}), s.t. WW^T = I$</p>
<p>step4: 拉格朗日法求解，可得：$X^TXW^T = \lambda W$</p>
<p>$W$的解为矩阵$X^TX$的特征向量。</p>
<h3 id="与SVD的关系"><a href="#与SVD的关系" class="headerlink" title="与SVD的关系"></a>与SVD的关系</h3><p>奇异值分解，对于矩阵X，其奇异值分解为: $X = U\Sigma V^T$</p>
<p>而矩阵$X^TX = (U\Sigma V)^TU\Sigma V^T = V\Sigma U^TU\Sigma V^T = V\Sigma^2 V^T$</p>
<p>因此矩阵$X^TX$的特征值构成的矩阵$V$即为矩阵$X$奇异值分解后的右特征矩阵。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris[<span class="string">'data'</span>]</span><br><span class="line">Y = iris[<span class="string">'target'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''normalization mean = 0, std = 1'''</span></span><br><span class="line">X_normed = (X - X.mean(axis=<span class="number">0</span>)) / X.std(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'''SVD of X_normed'''</span></span><br><span class="line">U, Sigma, VT = np.linalg.svd(X_normed)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''take the vector from V'''</span></span><br><span class="line">W = VT.T[:<span class="number">2</span>,:]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''conduct PCA 降维'''</span></span><br><span class="line">X_pca = X_normed.dot(W.T)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''visualization'''</span></span><br><span class="line">plt.scatter(X_pca[:,<span class="number">0</span>],X_pca[:,<span class="number">1</span>], c=Y)</span><br></pre></td></tr></table></figure>

<p><img src="http://img.chsong.live/Blogs/PCA%E4%B8%8ESVD%E7%9A%84%E5%85%B3%E7%B3%BB/2.png-o" alt="png"></p>
<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>算法</tag>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>Transfer Component Analyze (TCA)</title>
    <url>/20201205_TCA/index.html</url>
    <content><![CDATA[<p><img src="http://img.chsong.live/Blogs/TCA/1.png-s" alt="TCA"></p>
<p>TCA属于基于特征的迁移学习方法。那么，它做了一件什么事呢？用通俗的语言来说，跟PCA很像：PCA是一个大矩阵进去，一个小矩阵出来，TCA呢，是两个大矩阵进去，两个小矩阵出来。从学术角度讲，TCA针对domain adaptation问题中，源域和目标域处于不同数据分布时，将两个领域的数据一起映射到一个高维的再生核希尔伯特空间。在此空间中，最小化源和目标的数据距离，同时最大程度地保留它们各自的内部属性。直观地理解就是，在现在这个维度上不好最小化它们的距离，那么我就找个映射，在映射后的空间上让它们最接近，那么我不就可以进行分类了吗。</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.mlab <span class="keyword">as</span> mlab</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
<p>本文是在阿里天池实验室平台上实现的，数据集是我自己随机生成的模拟数据集，数据集在阿里天池平台，文末关注微信公众号【一切皆可解读】，回复关键词【XZ002】查看或下载。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">source = pd.read_csv(<span class="string">'datalab/48363/TCA_source.csv'</span>, sep = <span class="string">','</span>).values</span><br><span class="line">target = pd.read_csv(<span class="string">'datalab/48363/TCA_target.csv'</span>, sep = <span class="string">','</span>).values</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(source[<span class="number">0</span>:<span class="number">100</span>,<span class="number">2</span>],source[<span class="number">0</span>:<span class="number">100</span>,<span class="number">3</span>], c=<span class="string">''</span>,marker=<span class="string">'o'</span>, alpha=<span class="number">0.7</span>, edgecolors=<span class="string">'r'</span>)</span><br><span class="line">plt.scatter(source[<span class="number">100</span>:,<span class="number">2</span>],source[<span class="number">100</span>:,<span class="number">3</span>], c=<span class="string">''</span>,marker=<span class="string">'*'</span>, alpha=<span class="number">0.7</span>, edgecolors=<span class="string">'r'</span>)</span><br><span class="line">plt.scatter(target[<span class="number">0</span>:<span class="number">100</span>,<span class="number">2</span>],target[<span class="number">0</span>:<span class="number">100</span>,<span class="number">3</span>], c=<span class="string">''</span>,marker=<span class="string">'^'</span>, alpha=<span class="number">0.7</span>, edgecolors=<span class="string">'b'</span>)</span><br><span class="line">plt.scatter(target[<span class="number">100</span>:,<span class="number">2</span>],target[<span class="number">100</span>:,<span class="number">3</span>], c=<span class="string">''</span>,marker=<span class="string">'s'</span>, alpha=<span class="number">0.7</span>, edgecolors=<span class="string">'b'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'x1'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'x2'</span>)</span><br><span class="line">plt.legend((<span class="string">'Pos. Source'</span>, <span class="string">'Neg. Source'</span>, <span class="string">'Pos. Target'</span>, <span class="string">'Neg. Target'</span>))</span><br><span class="line">```  </span><br><span class="line">![png](http://img.chsong.live/Blogs/TCA/<span class="number">2.</span>png-o)</span><br><span class="line">```python</span><br><span class="line">Source_X = source[:, <span class="number">2</span>:<span class="number">4</span>]</span><br><span class="line">Source_Y = source[:,<span class="number">1</span>]</span><br><span class="line">Target_X = target[:, <span class="number">2</span>:<span class="number">4</span>]</span><br><span class="line">Target_Y = target[:, <span class="number">1</span>]</span><br><span class="line">print(Source_X.shape, Source_Y.shape, Target_X.shape, Target_Y.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(200, 2) (200,) (200, 2) (200,)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''PCA'''</span></span><br><span class="line"><span class="comment"># center matrix for cov</span></span><br><span class="line">ns = nt = <span class="number">200</span></span><br><span class="line">n = ns + nt</span><br><span class="line">H = np.eye(n) - (<span class="number">1</span>/n) * np.ones((n,n))</span><br><span class="line">All_X = np.concatenate((Source_X, Target_X), axis = <span class="number">0</span>)</span><br><span class="line"><span class="comment"># All_X = (All_X - All_X.mean(axis=0)) / All_X.std(axis=0)  #归一化操作，可加可不加</span></span><br><span class="line">XHX = All_X.T.dot(H).dot(All_X)</span><br><span class="line">eig_values, eig_vectors = np.linalg.eig(XHX)</span><br><span class="line">print(eig_vectors)</span><br><span class="line">W = eig_vectors[:,<span class="number">1</span>][:,np.newaxis]</span><br><span class="line">print(W)</span><br></pre></td></tr></table></figure>
<pre><code>[[-0.82451726 -0.56583681]
 [ 0.56583681 -0.82451726]]
[[-0.56583681]
 [-0.82451726]]</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">All_X_PCA = W.T.dot(All_X.T).squeeze()</span><br><span class="line"><span class="comment">#################两个领域整体数据分布</span></span><br><span class="line">plt.figure()</span><br><span class="line">S_n, S_bins, S_patches = plt.hist(All_X_PCA[<span class="number">0</span>:<span class="number">200</span>], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">T_n, T_bins, T_patches = plt.hist(All_X_PCA[<span class="number">200</span>: ], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.title(<span class="string">'Principle Component Analysis'</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.ylabel(<span class="string">'PDF'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">S_mu, S_sigma = All_X_PCA[<span class="number">0</span>:<span class="number">200</span>].mean(), All_X_PCA[<span class="number">0</span>:<span class="number">200</span>].std()</span><br><span class="line">T_mu, T_sigma = All_X_PCA[<span class="number">200</span>: ].mean(), All_X_PCA[<span class="number">200</span>: ].std()</span><br><span class="line">S_y, T_y = mlab.normpdf(S_bins, S_mu, S_sigma), mlab.normpdf(T_bins, T_mu, T_sigma)</span><br><span class="line"></span><br><span class="line">plt.plot(S_bins, S_y, <span class="string">'r-'</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">plt.plot(T_bins, T_y, <span class="string">'b-'</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##################两个领域，正负类别数据的分布</span></span><br><span class="line">plt.figure()</span><br><span class="line">S_P_n, S_P_bins, S_P_patches = plt.hist(All_X_PCA[<span class="number">0</span>:<span class="number">100</span>], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">S_N_n, S_N_bins, S_N_patches = plt.hist(All_X_PCA[<span class="number">100</span>:<span class="number">200</span>], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">T_P_n, T_P_bins, T_P_patches = plt.hist(All_X_PCA[<span class="number">200</span>:<span class="number">300</span>], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">T_N_n, T_N_bins, T_N_patches = plt.hist(All_X_PCA[<span class="number">300</span>: ], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line">S_P_mu, S_P_sigma = All_X_PCA[<span class="number">0</span>:<span class="number">100</span>].mean(), All_X_PCA[<span class="number">0</span>:<span class="number">100</span>].std()</span><br><span class="line">S_N_mu, S_N_sigma = All_X_PCA[<span class="number">100</span>:<span class="number">200</span>].mean(), All_X_PCA[<span class="number">100</span>:<span class="number">200</span>].std()</span><br><span class="line">T_P_mu, T_P_sigma = All_X_PCA[<span class="number">200</span>:<span class="number">300</span>].mean(), All_X_PCA[<span class="number">200</span>:<span class="number">300</span>].std()</span><br><span class="line">T_N_mu, T_N_sigma = All_X_PCA[<span class="number">300</span>: ].mean(), All_X_PCA[<span class="number">300</span>: ].std()</span><br><span class="line">S_P_y, T_P_y = mlab.normpdf(S_P_bins, S_P_mu, S_P_sigma), mlab.normpdf(T_P_bins, T_P_mu, T_P_sigma)</span><br><span class="line">S_N_y, T_N_y = mlab.normpdf(S_N_bins, S_N_mu, S_N_sigma), mlab.normpdf(T_N_bins, T_N_mu, T_N_sigma)</span><br><span class="line"></span><br><span class="line">plt.plot(S_P_bins, S_P_y/<span class="number">10</span>, <span class="string">'r+'</span>, alpha = <span class="number">0.4</span>)</span><br><span class="line">plt.plot(S_N_bins, S_N_y/<span class="number">10</span>, <span class="string">'rx'</span>, alpha = <span class="number">0.4</span>)</span><br><span class="line">plt.plot(T_P_bins, T_P_y/<span class="number">10</span>, <span class="string">'b+'</span>, alpha = <span class="number">0.4</span>)</span><br><span class="line">plt.plot(T_N_bins, T_N_y/<span class="number">10</span>, <span class="string">'bx'</span>, alpha = <span class="number">0.4</span>)</span><br><span class="line">plt.legend([<span class="string">'Source'</span>, <span class="string">'Target'</span>, <span class="string">'Pos. Source'</span>, <span class="string">'Neg. Source'</span>, <span class="string">'Pos. Target'</span>, <span class="string">'Neg. Target'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://img.chsong.live/Blogs/TCA/3.png-o" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">All_X = All_X.reshape(<span class="number">-1</span>, n)</span><br><span class="line">All_X /= np.linalg.norm(All_X, axis=<span class="number">0</span>)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Gaussian Kernel</span></span><br><span class="line"><span class="string">X: mxn</span></span><br><span class="line"><span class="string">m: num of features</span></span><br><span class="line"><span class="string">n: num of instances</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernel</span><span class="params">(kernel_type, X, gamma = <span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> kernel_type == <span class="string">'linear'</span>:</span><br><span class="line">        K = np.dot(X.T, X)</span><br><span class="line">    <span class="keyword">elif</span> kernel_type == <span class="string">'rbf'</span>:</span><br><span class="line">        D = np.sum(X.T**<span class="number">2</span>, axis=<span class="number">1</span>).reshape(n,<span class="number">-1</span>).dot(np.ones((<span class="number">1</span>,n))) + \</span><br><span class="line">            np.ones((n, <span class="number">1</span>)).dot(np.sum(X.T**<span class="number">2</span>, axis=<span class="number">1</span>).reshape(<span class="number">-1</span>,n)) - <span class="number">2</span>*X.T.dot(X)</span><br><span class="line">        K = np.exp(-gamma * D)</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="string">'''Construct Kernel Matrix K of All_X'''</span></span><br><span class="line">K = kernel(<span class="string">'rbf'</span>, All_X, gamma = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'''Construct Matrix L'''</span></span><br><span class="line">e = np.concatenate((np.ones(ns)/ns, -np.ones(nt)/nt)).reshape(n,<span class="number">-1</span>)</span><br><span class="line">L = e.dot(e.T)</span><br><span class="line">L /= np.linalg.norm(L)</span><br><span class="line"></span><br><span class="line"><span class="string">'''Construct the Matrix that need to be decomposed'''</span></span><br><span class="line">lamda = <span class="number">1</span></span><br><span class="line">M = np.linalg.pinv(K.dot(L).dot(K.T) + lamda * np.eye(n)).dot(K).dot(H).dot(K.T)</span><br><span class="line"></span><br><span class="line">eig_values, eig_vectors = np.linalg.eig(M)</span><br><span class="line">ind = np.argsort(eig_values)</span><br><span class="line">A = eig_vectors[:,ind[<span class="number">-1</span>]].reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<pre><code class="python">All_X_TCA = A.T.dot(K).squeeze()

plt.figure()
S_n, S_bins, S_patches = plt.hist(All_X_TCA[<span class="number">0</span>:<span class="number">200</span>], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)
T_n, T_bins, T_patches = plt.hist(All_X_TCA[<span class="number">200</span>: ], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)
plt.close()

plt.figure()
plt.title(<span class="string">'Transfer Component Analysis'</span>)
plt.xticks([])
plt.yticks([])
plt.ylabel(<span class="string">'PDF'</span>)
plt.xlabel(<span class="string">'x'</span>)
S_mu, S_sigma = All_X_TCA[<span class="number">0</span>:<span class="number">200</span>].mean(), All_X_TCA[<span class="number">0</span>:<span class="number">200</span>].std()
T_mu, T_sigma = All_X_TCA[<span class="number">200</span>: ].mean(), All_X_TCA[<span class="number">200</span>: ].std()
S_y, T_y = mlab.normpdf(S_bins, S_mu, S_sigma), mlab.normpdf(T_bins, T_mu, T_sigma)

plt.plot(S_bins, S_y, <span class="string">'r-'</span>, alpha = <span class="number">0.5</span>)
plt.plot(T_bins, T_y, <span class="string">'b-'</span>, alpha = <span class="number">0.5</span>)

<span class="comment">##################两个领域，正负类别数据的分布</span>
plt.figure()
S_P_n, S_P_bins, S_P_patches = plt.hist(All_X_TCA[<span class="number">0</span>:<span class="number">100</span>], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)
S_N_n, S_N_bins, S_N_patches = plt.hist(All_X_TCA[<span class="number">100</span>:<span class="number">200</span>], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)
T_P_n, T_P_bins, T_P_patches = plt.hist(All_X_TCA[<span class="number">200</span>:<span class="number">300</span>], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)
T_N_n, T_N_bins, T_N_patches = plt.hist(All_X_TCA[<span class="number">300</span>: ], bins=<span class="number">50</span>, alpha = <span class="number">0.5</span>)
plt.close()

S_P_mu, S_P_sigma = All_X_TCA[<span class="number">0</span>:<span class="number">100</span>].mean(), All_X_TCA[<span class="number">0</span>:<span class="number">100</span>].std()
S_N_mu, S_N_sigma = All_X_TCA[<span class="number">100</span>:<span class="number">200</span>].mean(), All_X_TCA[<span class="number">100</span>:<span class="number">200</span>].std()
T_P_mu, T_P_sigma = All_X_TCA[<span class="number">200</span>:<span class="number">300</span>].mean(), All_X_TCA[<span class="number">200</span>:<span class="number">300</span>].std()
T_N_mu, T_N_sigma = All_X_TCA[<span class="number">300</span>: ].mean(), All_X_TCA[<span class="number">300</span>: ].std()
S_P_y, T_P_y = mlab.normpdf(S_P_bins, S_P_mu, S_P_sigma), mlab.normpdf(T_P_bins, T_P_mu, T_P_sigma)
S_N_y, T_N_y = mlab.normpdf(S_N_bins, S_N_mu, S_N_sigma), mlab.normpdf(T_N_bins, T_N_mu, T_N_sigma)

plt.plot(S_P_bins, S_P_y/<span class="number">10</span>, <span class="string">'r+'</span>, alpha = <span class="number">0.4</span>)
plt.plot(S_N_bins, S_N_y/<span class="number">10</span>, <span class="string">'rx'</span>, alpha = <span class="number">0.4</span>)
plt.plot(T_P_bins, T_P_y/<span class="number">10</span>, <span class="string">'b+'</span>, alpha = <span class="number">0.4</span>)
plt.plot(T_N_bins, T_N_y/<span class="number">10</span>, <span class="string">'bx'</span>, alpha = <span class="number">0.4</span>)
plt.legend([<span class="string">'Source'</span>, <span class="string">'Target'</span>, <span class="string">'Pos. Source'</span>, <span class="string">'Neg. Source'</span>, <span class="string">'Pos. Target'</span>, <span class="string">'Neg. Target'</span>])
plt.show()</code></pre>
<p><img src="http://img.chsong.live/Blogs/TCA/4.png-o" alt="png"></p>
<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>算法</tag>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>Joint Distribution Adaptation (JDA)</title>
    <url>/20201205_%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB_%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0_JDA/index.html</url>
    <content><![CDATA[<p><img src="https://img.chsong.live/Blogs/JDA/1.png-s" alt="JDA"></p>
<p>JDA方法首次发表于2013年的ICCV（计算机视觉领域顶会，与CVPR类似），它的作者是清华大学的博士生（现为清华大学助理教授）龙明盛。联合分布适配方法（joint distribution adaptation,JDA）解决的也是迁移学习中一类很大的问题：domain adaptation。</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> scio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> scipy.io</span><br><span class="line"><span class="keyword">import</span> scipy.linalg</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
<p>数据集是我自己处理好的手写数字识别数据集，数据集在阿里天池平台，文末关注微信公众号【一切皆可解读】，回复关键词【XZ003】查看或下载。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">usps = scio.loadmat(<span class="string">'datalab/48612/usps.mat.bin'</span>)</span><br><span class="line">mnist = scio.loadmat(<span class="string">'datalab/48612/mnist.mat.bin'</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'''Visualization'''</span></span><br><span class="line"><span class="comment">## images in MNIST</span></span><br><span class="line">mnist_rdm = np.random.randint(<span class="number">2000</span>, size=<span class="number">16</span>)</span><br><span class="line">mnist_labels = mnist[<span class="string">'Y'</span>][mnist_rdm].reshape(<span class="number">4</span>,<span class="number">4</span>).T - <span class="number">1</span></span><br><span class="line">mnist_ims = mnist[<span class="string">'X'</span>][:,mnist_rdm].T</span><br><span class="line">mnist_ims = np.array([im.reshape(<span class="number">16</span>,<span class="number">16</span>) <span class="keyword">for</span> im <span class="keyword">in</span> mnist_ims])</span><br><span class="line">mnist_ims = functools.reduce(<span class="keyword">lambda</span> x, y : np.concatenate((x, y),axis=<span class="number">1</span>), np.array([mnist_ims[i*<span class="number">4</span>:(i+<span class="number">1</span>)*<span class="number">4</span>].reshape(<span class="number">4</span>*<span class="number">16</span>,<span class="number">-1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)]))</span><br><span class="line">print(mnist_labels)</span><br><span class="line">plt.imshow(mnist_ims, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">## images in USPS</span></span><br><span class="line">usps_rdm = np.random.randint(<span class="number">1800</span>, size=<span class="number">16</span>)</span><br><span class="line">usps_labels = usps[<span class="string">'Y'</span>][usps_rdm].reshape(<span class="number">4</span>,<span class="number">4</span>).T - <span class="number">1</span></span><br><span class="line">usps_ims = usps[<span class="string">'X'</span>][:,usps_rdm].T</span><br><span class="line">usps_ims = np.array([im.reshape(<span class="number">16</span>,<span class="number">16</span>) <span class="keyword">for</span> im <span class="keyword">in</span> usps_ims])</span><br><span class="line">usps_ims = functools.reduce(<span class="keyword">lambda</span> x, y : np.concatenate((x, y),axis=<span class="number">1</span>), np.array([usps_ims[i*<span class="number">4</span>:(i+<span class="number">1</span>)*<span class="number">4</span>].reshape(<span class="number">4</span>*<span class="number">16</span>,<span class="number">-1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)]))</span><br><span class="line">print(usps_labels)</span><br><span class="line">plt.imshow(usps_ims, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>[[2 8 7 9]
 [1 3 3 1]
 [5 4 8 2]
 [2 2 4 4]]</code></pre><p><img src="https://img.chsong.live/Blogs/JDA/2.png-o" alt="png"></p>
<pre><code>[[1 4 0 0]
 [2 0 0 4]
 [5 2 7 0]
 [9 2 8 3]]</code></pre><p><img src="https://img.chsong.live/Blogs/JDA/3.png-o" alt="png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Kernels</span></span><br><span class="line"><span class="string">X: m x n</span></span><br><span class="line"><span class="string">m: num of features</span></span><br><span class="line"><span class="string">n: num of instances</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernel</span><span class="params">(kernel_type, X, gamma = <span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> kernel_type == <span class="string">'original'</span>:</span><br><span class="line">        K = X</span><br><span class="line">    <span class="keyword">elif</span> kernel_type == <span class="string">'linear'</span>:</span><br><span class="line">        K = np.dot(X.T, X)</span><br><span class="line">    <span class="keyword">elif</span> kernel_type == <span class="string">'rbf'</span>:</span><br><span class="line">        D = np.sum(X.T**<span class="number">2</span>, axis=<span class="number">1</span>).reshape(X.shape[<span class="number">1</span>],<span class="number">-1</span>).dot(np.ones((<span class="number">1</span>,X.shape[<span class="number">1</span>]))) + \</span><br><span class="line">            np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>)).dot(np.sum(X.T**<span class="number">2</span>, axis=<span class="number">1</span>).reshape(<span class="number">-1</span>,X.shape[<span class="number">1</span>])) - <span class="number">2</span>*X.T.dot(X)</span><br><span class="line">        K = np.exp(-gamma * D)</span><br><span class="line">    <span class="keyword">return</span> K</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">JDA</span><span class="params">(source, target, lamda, gamma, kernel_type=<span class="string">'rbf'</span>, iterations=<span class="number">10</span>, Y_pseudo=None)</span>:</span></span><br><span class="line">    X_source, Y_source = source[<span class="string">'X'</span>], source[<span class="string">'Y'</span>]</span><br><span class="line">    X_target, Y_target = target[<span class="string">'X'</span>], target[<span class="string">'Y'</span>]</span><br><span class="line">    ns, nt = len(Y_source), len(Y_target)</span><br><span class="line">    n = ns + nt</span><br><span class="line">    <span class="string">'''concatenate the source and target data'''</span></span><br><span class="line">    X = np.concatenate((X_source, X_target), axis = <span class="number">1</span>)</span><br><span class="line">    <span class="string">'''normlization is important, the acc is very low without this step'''</span></span><br><span class="line">    X /= np.linalg.norm(X, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="string">'''construct the matrix H'''</span></span><br><span class="line">    H = np.eye(n) - (<span class="number">1</span>/n) * np.ones((n,n))</span><br><span class="line">    <span class="string">'''construct the matrix M0'''</span></span><br><span class="line">    e0 = np.concatenate((np.ones((ns,<span class="number">1</span>))/ns, -np.ones((nt,<span class="number">1</span>))/nt), axis=<span class="number">0</span>)</span><br><span class="line">    M0 = e0.dot(e0.T) </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> Y_pseudo <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        C = len(np.unique(Y_source))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(iterations):</span><br><span class="line">            print(<span class="string">'    iteration:'</span>,i+<span class="number">1</span>, <span class="string">' '</span>, end=<span class="string">''</span>)</span><br><span class="line">            N = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> range(<span class="number">1</span>, C+<span class="number">1</span>):</span><br><span class="line">                e = np.zeros((n, <span class="number">1</span>))</span><br><span class="line">                e[np.where(Y_source==c)] = <span class="number">1</span> / len(Y_source[np.where(Y_source==c)])</span><br><span class="line">                e[np.where(Y_pseudo==c)[<span class="number">0</span>] + ns] = <span class="number">-1</span> / len(Y_pseudo[np.where(Y_pseudo==c)])</span><br><span class="line">                N += e.dot(e.T)</span><br><span class="line"></span><br><span class="line">            M = M0 + N</span><br><span class="line">            M /= np.linalg.norm(M,<span class="string">'fro'</span>)</span><br><span class="line">            n_eye = X.shape[<span class="number">0</span>] <span class="keyword">if</span> kernel_type == <span class="string">'original'</span> <span class="keyword">else</span> n</span><br><span class="line">            K = kernel(kernel_type, X, gamma)</span><br><span class="line">            eig_vals, eig_vecs = np.linalg.eig(np.linalg.pinv(np.linalg.multi_dot([K, H, K.T])).dot(np.linalg.multi_dot([K, M, K.T]) + lamda * np.eye(n_eye)))</span><br><span class="line">            ind = np.argsort(eig_vals)</span><br><span class="line">            A = eig_vecs[:,ind[:<span class="number">100</span>]]</span><br><span class="line">            Z = A.T.dot(K)</span><br><span class="line">            Z /= np.linalg.norm(Z, axis = <span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            X_source_JDA, X_target_JDA = Z[:,:ns], Z[:,ns:]</span><br><span class="line">            </span><br><span class="line">            pseudo = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">            pseudo.fit(X_source_JDA.T, Y_source.flatten())</span><br><span class="line">            Y_pseudo = pseudo.predict(X_target_JDA.T)</span><br><span class="line">            pseudo_acc = sklearn.metrics.accuracy_score(Y_target.flatten(), Y_pseudo)</span><br><span class="line">            print(<span class="string">'acc:'</span>,pseudo_acc)</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> X_source_JDA, X_target_JDA</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">### '''两个领域，分别是mnist, usps. 可以在增加其他数据集，构造多个领域'''</span></span><br><span class="line"><span class="string">'''各个领域分别作为源领域和目标领域，'''</span></span><br><span class="line">domain_names = [<span class="string">'mnist'</span>, <span class="string">'usps'</span>]</span><br><span class="line">domains = [mnist, usps]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(domains)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(domains)):</span><br><span class="line">        <span class="keyword">if</span> i != j:</span><br><span class="line">            print(<span class="string">'\n from'</span>, domain_names[i], <span class="string">'to'</span>, domain_names[j])</span><br><span class="line">            </span><br><span class="line">            source, target = domains[i], domains[j]</span><br><span class="line">            baseline = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">            baseline.fit(source[<span class="string">'X'</span>].T, source[<span class="string">'Y'</span>].flatten())</span><br><span class="line">            Y_pseudo_target = baseline.predict(target[<span class="string">'X'</span>].T)</span><br><span class="line">            baseline_acc = sklearn.metrics.accuracy_score(target[<span class="string">'Y'</span>].flatten(), Y_pseudo_target)</span><br><span class="line">            print(<span class="string">'    acc of baseline 1-NN:'</span>, baseline_acc)</span><br><span class="line">            </span><br><span class="line">            X_JDA_source, X_JDA_target = JDA(source, target, lamda=<span class="number">1</span>, gamma=<span class="number">1</span>, kernel_type=<span class="string">'rbf'</span>, iterations=<span class="number">5</span>, Y_pseudo=Y_pseudo_target)</span><br><span class="line">            jda = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">            jda.fit(X_JDA_source.T, source[<span class="string">'Y'</span>].flatten())</span><br><span class="line">            Y_pseudo_target = jda.predict(X_JDA_target.T)</span><br><span class="line">            jda_acc = sklearn.metrics.accuracy_score(target[<span class="string">'Y'</span>].flatten(), Y_pseudo_target)</span><br><span class="line">            print(<span class="string">'    acc of jda:'</span>, jda_acc)</span><br></pre></td></tr></table></figure>
<p>from mnist to usps<br>    acc of baseline 1-NN: 0.644444444444<br>    iteration: 1  acc: 0.743333333333<br>    iteration: 2  acc: 0.764444444444<br>    iteration: 3  acc: 0.756666666667<br>    iteration: 4  acc: 0.755555555556<br>    iteration: 5  acc: 0.757777777778<br>    acc of jda: 0.757777777778</p>
<p>from usps to mnist<br>    acc of baseline 1-NN: 0.3585<br>    iteration: 1  acc: 0.583<br>    iteration: 2  acc: 0.6165<br>    iteration: 3  acc: 0.613<br>    iteration: 4  acc: 0.6135<br>    iteration: 5  acc: 0.619<br>    acc of jda: 0.619</p>
<p>效果比JDA原文里面的实验结果好很多，尤其是从mnist到usps，可能是因为数据的原因，虽然都是随即抽取的样本，mnist：2000，usps：1800. 跟原文还是有一些差别。</p>
<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>算法</tag>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>变长循环神经网络 [Pytorch]</title>
    <url>/20201205_%E5%8F%98%E9%95%BF%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html</url>
    <content><![CDATA[<p><img src="https://img.chsong.live/Blogs/%E5%8F%98%E9%95%BF%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.png-s" alt="LSTM"><br>在使用循环神经网络时，经常碰到可变长数据，就是每一个样本的时间步是不一样的。这里总结一下pytorch里面的处理方法。</p>
<a id="more"></a>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''导入相关包'''</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.utils.rnn <span class="keyword">as</span> rnn_utils</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">人工给出一小部分数据做示例</span></span><br><span class="line"><span class="string">这里，一共包含7个数据样本，每个样本的长度不一样，分别是:7,6,5,...,1</span></span><br><span class="line"><span class="string">数据的维度为1维</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">train_x = [torch.Tensor([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]),</span><br><span class="line">           torch.Tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]),</span><br><span class="line">           torch.Tensor([<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]),</span><br><span class="line">           torch.Tensor([<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]),</span><br><span class="line">           torch.Tensor([<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>]),</span><br><span class="line">           torch.Tensor([<span class="number">6</span>, <span class="number">6</span>]),</span><br><span class="line">           torch.Tensor([<span class="number">7</span>])]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">长度不一样，在代码中没法处理，因此必须将短的数据增长到与最长的数据长度一样</span></span><br><span class="line"><span class="string">一般都是补0，在pytorch里面有专门的函数: pad_sequence</span></span><br><span class="line"><span class="string">这样一来，数据将变为：</span></span><br><span class="line"><span class="string">[torch.Tensor([1, 1, 1, 1, 1, 1, 1]),</span></span><br><span class="line"><span class="string"> torch.Tensor([2, 2, 2, 2, 2, 2, 0]),</span></span><br><span class="line"><span class="string"> torch.Tensor([3, 3, 3, 3, 3, 0, 0]),</span></span><br><span class="line"><span class="string"> torch.Tensor([4, 4, 4, 4, 0, 0, 0]),</span></span><br><span class="line"><span class="string"> torch.Tensor([5, 5, 5, 0, 0, 0, 0]),</span></span><br><span class="line"><span class="string"> torch.Tensor([6, 6, 0, 0, 0, 0, 0]),</span></span><br><span class="line"><span class="string"> torch.Tensor([7, 0, 0, 0, 0, 0, 0])]</span></span><br><span class="line"><span class="string"> 这里我们只是给出例子，看看pad_sequence的作用，为了能够训练模型，需要将其封装到数据集Dataset里面，方便DataLoader</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">x = rnn_utils.pad_sequence(train_x, batch_first=<span class="literal">True</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.],
        [ 2.,  2.,  2.,  2.,  2.,  2.,  0.],
        [ 3.,  3.,  3.,  3.,  3.,  0.,  0.],
        [ 4.,  4.,  4.,  4.,  0.,  0.,  0.],
        [ 5.,  5.,  5.,  0.,  0.,  0.,  0.],
        [ 6.,  6.,  0.,  0.,  0.,  0.,  0.],
        [ 7.,  0.,  0.,  0.,  0.,  0.,  0.]])</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">封装到数据集MyData</span></span><br><span class="line"><span class="string">实际上是定义了一个collate_fn函数，它是用来控制在DataLoader中，load数据的时候，返回数据的格式</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyData</span><span class="params">(data.Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_seq)</span>:</span></span><br><span class="line">        self.data_seq = data_seq</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.data_seq)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.data_seq[idx]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(data)</span>:</span></span><br><span class="line">    data.sort(key=<span class="keyword">lambda</span> x: len(x), reverse=<span class="literal">True</span>) <span class="comment">#将数据按数据长度从大到小排列</span></span><br><span class="line">    data_length = [len(sq) <span class="keyword">for</span> sq <span class="keyword">in</span> data]</span><br><span class="line">    data = rnn_utils.pad_sequence(data, batch_first=<span class="literal">True</span>, padding_value=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> data.unsqueeze(<span class="number">-1</span>), data_length <span class="comment">#这里的unsqueeze是为了将数据从7x7变为7x7x1，符合模型的输入数据格式，共7个样本，维度为1，pad之后的"长度"为7</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">测试</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    </span><br><span class="line">    data = MyData(train_x) <span class="comment">#将原始数据通过MyData封装</span></span><br><span class="line">    </span><br><span class="line">    data_loader = DataLoader(data, batch_size=<span class="number">3</span>, shuffle=<span class="literal">True</span>,collate_fn=collate_fn) <span class="comment">#封装进DataLoader，通过collate_fn控制返回数据的格式，即对每一个样本都进行pad</span></span><br><span class="line">    </span><br><span class="line">    batch_x, batch_x_len = iter(data_loader).next()</span><br><span class="line">    </span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    这里batch_size=3，因此batch_x的格式为：</span></span><br><span class="line"><span class="string">    [[[ 1.],  [1.],  [1.],  [1.],  [1.],  [1.],  [1.]],</span></span><br><span class="line"><span class="string">     [[ 3.],  [3.],  [3.],  [3.],  [3.],  [0.],  [0.]],</span></span><br><span class="line"><span class="string">     [[ 6.],  [6.],  [0.],  [0.],  [0.],  [0.],  [0.]]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    为了不让后面的0参与运算，即运算完所有的非0数据后就停止</span></span><br><span class="line"><span class="string">    pytorch里面需要对batch_x进行pack，即压缩</span></span><br><span class="line"><span class="string">    压缩后的数据格式，以及为设么这么压缩，和pytorch里面循环神经网络的工作原理有关，这里不做详细介绍</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, batch_x_len, batch_first=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    构建模型，初始化h0,c0</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    net = nn.LSTM(<span class="number">1</span>, <span class="number">10</span>, <span class="number">2</span>, batch_first=<span class="literal">True</span>)</span><br><span class="line">    h0 = torch.rand(<span class="number">2</span>, <span class="number">3</span>, <span class="number">10</span>)</span><br><span class="line">    c0 = torch.rand(<span class="number">2</span>, <span class="number">3</span>, <span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="string">'''通过LSTM计算'''</span></span><br><span class="line">    out, (h1, c1) = net(batch_x_pack, (h0, c0))</span><br><span class="line">    </span><br><span class="line">    <span class="string">'''这里，模型输出的数据和输入的数据格式一样，都是被压缩过的，这里需要将其还原成正常的矩阵形式，使用pad_packed_sequence函数'''</span></span><br><span class="line">    out_pad, out_len = rnn_utils.pad_packed_sequence(out, batch_first=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    print(out_pad)</span><br><span class="line">    print(<span class="string">'END'</span>)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([[[ 0.0490,  0.1100,  0.0750,  0.0998,  0.3622, -0.0891,  0.1562, 0.0122, -0.1227,  0.0537],
         [ 0.0113,  0.0290,  0.0375,  0.1051,  0.2836, -0.1209,  0.1458, -0.0848, -0.1296, -0.0788],
         [ 0.0048, -0.0075,  0.0173,  0.0673,  0.2713, -0.1431,  0.1392, -0.1227, -0.1214, -0.1425],
         [ 0.0102, -0.0246,  0.0090,  0.0291,  0.2600, -0.1579,  0.1342, -0.1392, -0.1135, -0.1720],
         [ 0.0177, -0.0328,  0.0058, -0.0016,  0.2524, -0.1678,  0.1313, -0.1480, -0.1091, -0.1863],
         [ 0.0240, -0.0371,  0.0048, -0.0244,  0.2475, -0.1742,  0.1300, -0.1542, -0.1074, -0.1939],
         [ 0.0286, -0.0398,  0.0047, -0.0408,  0.2445, -0.1782,  0.1298, -0.1592, -0.1071, -0.1983]],

        [[ 0.2161, -0.0114,  0.1041,  0.0859,  0.0486, -0.0040,  0.2124, 0.1901,  0.1633,  0.1281],
         [ 0.1089, -0.0357,  0.0969,  0.0758,  0.1588, -0.1085,  0.1722, 0.0266, -0.0036, -0.0442],
         [ 0.0438, -0.0525,  0.0566,  0.0414,  0.2152, -0.1581,  0.1527, -0.0615, -0.0681, -0.1262],
         [ 0.0199, -0.0631,  0.0303,  0.0025,  0.2376, -0.1802,  0.1418, -0.1058, -0.0890, -0.1643],
         [ 0.0137, -0.0696,  0.0154, -0.0301,  0.2450, -0.1906,  0.1362, -0.1309, -0.0954, -0.1821],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 0.0000,  0.0000,  0.0000]],

        [[-0.0518,  0.0285,  0.1449,  0.1145,  0.2673, -0.0603,  0.1157, .1086, -0.0482, -0.0614],
         [-0.0578, -0.0089,  0.0664,  0.0769,  0.2777, -0.1151,  0.1328, -0.0094, -0.0666, -0.1451],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 0.0000,  0.0000,  0.0000]]])
END</code></pre><p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>算法</tag>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Knowledge Tracing [Pytorch]</title>
    <url>/20201124_DKT-Pytorch/index.html</url>
    <content><![CDATA[<p><img src="http://img.chsong.live/Blogs/DKT-pytorch/1.png-o" alt="DKT"></p>
<p>知识追踪（Knowledge Tracing）是根据学生过去的答题情况对学生的知识掌握情况进行建模，从而得到学生当前知识状态表示的一种技术。将深度学习的方法引入知识追踪最早出现于发表在NeurIPS 2015上的一篇论文《Deep Knowledge Tracing》，作者来自斯坦福大学。在这篇论文中，作者提出了使用深度知识追踪（Deep Knowledge Tracing, DKT）的概念，利用RNN对学生的学习情况进行建模，之后引出了一系列工作，2019年已经有使用Transformer代替RNN和LSTM并且达到了SOTA的论文。DKT作为知识追踪模型深度化的开山之作，在几乎所有的深度知识追踪模型中都作为baseline，而DKT作者给出的模型实现是基于lua语言的，为了能够让更多的研究人员更方便的使用，这里给出一种python的实现，采用的是pytorch框架。</p>
<a id="more"></a>

<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>模型代码已经发布在github上，可点击<a href="https://github.com/chsong513/DeepKnowledgeTracing-DKT-Pytorch" target="_blank" rel="noopener">这里</a>查看和下载具体代码。</p>
<p>或者可以直接通过如下命令直接下载到本地：</p>
<blockquote>
<p>git clone <a href="https://github.com/chsong513/DeepKnowledgeTracing-DKT-Pytorch.git" target="_blank" rel="noopener">https://github.com/chsong513/DeepKnowledgeTracing-DKT-Pytorch.git</a></p>
</blockquote>
<p>具体运行和使用方法参考GitHub项目上ReadMe。</p>
<h2 id="项目结构-DKT"><a href="#项目结构-DKT" class="headerlink" title="项目结构-DKT"></a>项目结构-DKT</h2><p>在DKT文件夹下包括两个文件夹：KTDataset和KnowledgeTracing。</p>
<p><img src="http://img.chsong.live/Blogs/DKT-pytorch/2.png-o" alt=""></p>
<h3 id="数据集-KTDataset"><a href="#数据集-KTDataset" class="headerlink" title="数据集-KTDataset"></a>数据集-KTDataset</h3><p><img src="http://img.chsong.live/Blogs/DKT-pytorch/4.png-o" alt=""></p>
<p>KTDataset文件夹下有6个常用的知识追踪数据集，数据都已经处理成三行格式：</p>
<blockquote>
<p>第一行：答题数<br>第二行：题目编号<br>第三行：答题结果，0表示错，1表示对</p>
</blockquote>
<p>举例：<br><img src="http://img.chsong.live/Blogs/DKT-pytorch/3.png-o" alt=""></p>
<p>Note：可根据需要，按照数据格式自行添加新的数据集。</p>
<h3 id="模型结构-KnowledgeTracing"><a href="#模型结构-KnowledgeTracing" class="headerlink" title="模型结构-KnowledgeTracing"></a>模型结构-KnowledgeTracing</h3><p><img src="http://img.chsong.live/Blogs/DKT-pytorch/5.png-o" alt=""></p>
<p>模型的整个流程都在KnowledgeTracing目录下，包括模型、参数设置、数据处理、模型训练和评估，分别在四个子目录下：model， Constant，data，evaluation。</p>
<h4 id="参数设置-Constant"><a href="#参数设置-Constant" class="headerlink" title="参数设置-Constant"></a>参数设置-Constant</h4><p>Constant下主要设置一些参数和超参数，超参数也分为四大块：数据集存储路径、数据集、题目数、模型超参数。</p>
<p>数据集存储路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Dpath = <span class="string">'../../KTDataset'</span></span><br></pre></td></tr></table></figure>
<p>数据集：一共包括6个数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">datasets = &#123;</span><br><span class="line">    <span class="string">'assist2009'</span> : <span class="string">'assist2009'</span>,</span><br><span class="line">    <span class="string">'assist2015'</span> : <span class="string">'assist2015'</span>,</span><br><span class="line">    <span class="string">'assist2017'</span> : <span class="string">'assist2017'</span>,</span><br><span class="line">    <span class="string">'static2011'</span> : <span class="string">'static2011'</span>,</span><br><span class="line">    <span class="string">'kddcup2010'</span> : <span class="string">'kddcup2010'</span>,</span><br><span class="line">    <span class="string">'synthetic'</span> : <span class="string">'synthetic'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>题目数：表示每个数据集里面题目的数量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numbers = &#123;</span><br><span class="line">    <span class="string">'assist2009'</span> : <span class="number">124</span>,  </span><br><span class="line">    <span class="string">'assist2015'</span> : <span class="number">100</span>,</span><br><span class="line">    <span class="string">'assist2017'</span> : <span class="number">102</span>,</span><br><span class="line">    <span class="string">'static2011'</span> : <span class="number">1224</span>, </span><br><span class="line">    <span class="string">'kddcup2010'</span> : <span class="number">661</span>,  </span><br><span class="line">    <span class="string">'synthetic'</span> : <span class="number">50</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>模型超参数：主要包括所用数据集、输入输出维度、学习率、最大步长、学习周期等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DATASET = datasets[<span class="string">'static2011'</span>]</span><br><span class="line">NUM_OF_QUESTIONS = numbers[<span class="string">'static2011'</span>]</span><br><span class="line"><span class="comment"># the max step of RNN model</span></span><br><span class="line">MAX_STEP = <span class="number">50</span></span><br><span class="line">BATCH_SIZE = <span class="number">64</span></span><br><span class="line">LR = <span class="number">0.002</span></span><br><span class="line">EPOCH = <span class="number">1000</span></span><br><span class="line"><span class="comment">#input dimension</span></span><br><span class="line">INPUT = NUM_OF_QUESTIONS * <span class="number">2</span></span><br><span class="line"><span class="comment"># embedding dimension</span></span><br><span class="line">EMBED = NUM_OF_QUESTIONS</span><br><span class="line"><span class="comment"># hidden layer dimension</span></span><br><span class="line">HIDDEN = <span class="number">200</span></span><br><span class="line"><span class="comment"># nums of hidden layers</span></span><br><span class="line">LAYERS = <span class="number">1</span></span><br><span class="line"><span class="comment"># output dimension</span></span><br><span class="line">OUTPUT = NUM_OF_QUESTIONS</span><br></pre></td></tr></table></figure>

<h4 id="模型实现-model"><a href="#模型实现-model" class="headerlink" title="模型实现-model"></a>模型实现-model</h4><p>模型在model目录下的RNNModel.py文件中实现，模型实际上就是一个简单的LSTM网络，其结构跟DKT原文中所讲述的结构一致，在LSTM模型最后添加了一个线性层和一个sigmoid激活函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DKT</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, hidden_dim, layer_dim, output_dim)</span>:</span></span><br><span class="line">        super(DKT, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.layer_dim = layer_dim</span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=<span class="literal">True</span>,nonlinearity=<span class="string">'tanh'</span>)</span><br><span class="line">        self.fc = nn.Linear(self.hidden_dim, self.output_dim)</span><br><span class="line">        self.sig = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        h0 = Variable(torch.zeros(self.layer_dim, x.size(<span class="number">0</span>), self.hidden_dim))</span><br><span class="line">        out,hn = self.rnn(x, h0)</span><br><span class="line">        res = self.sig(self.fc(out))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>

<h4 id="数据处理-data"><a href="#数据处理-data" class="headerlink" title="数据处理-data"></a>数据处理-data</h4><p>在data目录下包括三个文件：readdata.py、DKTDataSet.py、dataloader.py。它们的作用分别是定义数据的读取、pytorch框架下的数据集定义、以及pytorch框架下的dataloader的构造。</p>
<p><img src="http://img.chsong.live/Blogs/DKT-pytorch/6.png-o" alt=""></p>
<p><strong>readata</strong>: 在readata.py文件中，定义了一个类：DataReader，从名字可以看出这是一个用来读取数据的类。其中包含两个函数getTrainData()和getTestData()，分别是用来读取训练数据和测试数据。两个函数的定义其实一模一样，只是名字不一样用来区分训练和测试数据，这样的写法有些冗余，后面会再做一些优化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataReader</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, path, maxstep, numofques)</span>:</span></span><br><span class="line">        self.path = path</span><br><span class="line">        self.maxstep = maxstep</span><br><span class="line">        self.numofques = numofques</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTrainData</span><span class="params">(self)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTestData</span><span class="params">(self)</span>:</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>DataReader类有三个参数：</p>
<blockquote>
<p>path: 数据文件存储路径<br>maxstep: 最大序列长度<br>numofques: 此数据集中所有题目的总个数（去重后）</p>
</blockquote>
<p>获取与处理数据部分，以getTrainData()函数为例，getTestData()与其一样。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTrainData</span><span class="params">(self)</span>:</span></span><br><span class="line">    trainqus = np.array([])</span><br><span class="line">    trainans = np.array([])</span><br><span class="line">    <span class="keyword">with</span> open(self.path, <span class="string">'r'</span>) <span class="keyword">as</span> train:</span><br><span class="line">        <span class="keyword">for</span> len, ques, ans <span class="keyword">in</span> tqdm.tqdm(itertools.zip_longest(*[train] * <span class="number">3</span>), desc=<span class="string">'loading train data:    '</span>, mininterval=<span class="number">2</span>):</span><br><span class="line">            len = int(len.strip().strip(<span class="string">','</span>))</span><br><span class="line">            ques = np.array(ques.strip().strip(<span class="string">','</span>).split(<span class="string">','</span>)).astype(np.int)</span><br><span class="line">            ans = np.array(ans.strip().strip(<span class="string">','</span>).split(<span class="string">','</span>)).astype(np.int)</span><br><span class="line">            mod = <span class="number">0</span> <span class="keyword">if</span> len%self.maxstep == <span class="number">0</span> <span class="keyword">else</span> (self.maxstep - len%self.maxstep)</span><br><span class="line">            zero = np.zeros(mod) - <span class="number">1</span></span><br><span class="line">            ques = np.append(ques, zero)</span><br><span class="line">            ans = np.append(ans, zero)</span><br><span class="line">            trainqus = np.append(trainqus, ques).astype(np.int)</span><br><span class="line">            trainans = np.append(trainans, ans).astype(np.int)</span><br><span class="line">    <span class="keyword">return</span> trainqus.reshape([<span class="number">-1</span>, self.maxstep]), trainans.reshape([<span class="number">-1</span>, self.maxstep])</span><br></pre></td></tr></table></figure>
<p>在getTrainData()中，首先定义两个numpy数组trainqus和trainans，前者存储题目编号，后者存储对应的答题结果。然后打开文件开始读取数据。</p>
<p>因为数据是三行格式的，所以每一次读取三行，每次读取三行的实现方式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> len, ques, ans <span class="keyword">in</span> tqdm.tqdm(itertools.zip_longest(*[train] * <span class="number">3</span>), desc=<span class="string">'loading train data:    '</span>, mininterval=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>其中tqdm是进度条展示，可忽略，简化来看每次读取三行的方法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> len, ques, ans <span class="keyword">in</span> itertools.zip_longest(*[train] * <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>然后是对三行数据进行字符串处理，分别得到题目编号以及对应的答题结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ques = np.array(ques.strip().strip(<span class="string">','</span>).split(<span class="string">','</span>)).astype(np.int)</span><br><span class="line">ans = np.array(ans.strip().strip(<span class="string">','</span>).split(<span class="string">','</span>)).astype(np.int)</span><br></pre></td></tr></table></figure>
<p>然后是处理长度不一致的问题，将所有答题序列的长度都处理成maxstep的整数倍，长度不够的补0。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mod = <span class="number">0</span> <span class="keyword">if</span> len%self.maxstep == <span class="number">0</span> <span class="keyword">else</span> (self.maxstep - len%self.maxstep)</span><br><span class="line">zero = np.zeros(mod) - <span class="number">1</span></span><br><span class="line">ques = np.append(ques, zero)</span><br><span class="line">ans = np.append(ans, zero)</span><br></pre></td></tr></table></figure>
<p>举例：ques长度为18，设置maxstep为5，那么ques补充成maxstep的整数倍应该是4倍为20，所以ques应该补充两个0变成长度为20的序列；如果ques长度为11，那么补充4个0，长度变成15；ques长度为10，则不补充。</p>
<p>每一个ques的长度处理成maxstep的整数倍之后，添加到trainques数组中去，这样每一次添加都保证了trainques的长度为maxstep的整数倍。ans以及trainans的处理过程一样。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainqus = np.append(trainqus, ques).astype(np.int)</span><br><span class="line">trainans = np.append(trainans, ans).astype(np.int)</span><br></pre></td></tr></table></figure>
<p>最后对trainques和trainans进行reshape，处理成N*maxstep的矩阵形式，N即可看做学生个数。maxstep即为答题个数。</p>
<p>举例，数据形式的变化过程，比如设置maxstep为3，总题目数为5，现在有如下三个学生的原始答题记录：<br>学生1：<br>2<br>1 2<br>1 0<br>学生2：<br>4<br>2 4 1 3<br>0 1 1 0<br>学生3：<br>7<br>5 3 1 4 5 4 2<br>0 0 1 1 0 1 0</p>
<p>ques通过readata读取并处理之后会变成：<br>1 2 0<br>2 4 1<br>3 0 0<br>5 3 1<br>4 5 4<br>2 0 0</p>
<p><strong>DKTDataSet</strong>：要定义pytorch框架下的数据集，需要继承torch的Dataset类，覆写__init__、__len__以及__getitem__三个函数。还可以根据需要自己添加数据处理的函数，在DKTDataSet中添加的one-hot处理函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DKTDataSet</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ques, ans)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onehot</span><span class="params">(self, questions, answers)</span>:</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>在readdata处理好数据之后，我们在DKTDataSet中对其进行封装处理，直接返回题目的one-hot形式而不再是题目编号。</p>
<p>在__init__中做一些初始化操作，比入读进数据ques和ans，前者是题目编号，后者是答题结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ques, ans)</span>:</span></span><br><span class="line">    self.ques = ques</span><br><span class="line">    self.ans = ans</span><br></pre></td></tr></table></figure>

<p>__len__返回数据集的长度（大小），这里直接返回ques或者ans的行数，也就是学生数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> len(self.ques)</span><br></pre></td></tr></table></figure>

<p>__getitem__返回需要获取的某条数据，这里根据index参数直接返回对应的数据即可，这里我们返回前将数据通过自定义的onehot函数处理成one-hot的形式，并且将数据类型转换为FloatTensor。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">    questions = self.ques[index]</span><br><span class="line">    answers = self.ans[index]</span><br><span class="line">    onehot = self.onehot(questions, answers)</span><br><span class="line">    <span class="keyword">return</span> torch.FloatTensor(onehot.tolist())</span><br></pre></td></tr></table></figure>

<p>__onehot__是自定义的将题目编号转变成one-hot形式的函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">onehot</span><span class="params">(self, questions, answers)</span>:</span></span><br><span class="line">    result = np.zeros(shape=[C.MAX_STEP, <span class="number">2</span> * C.NUM_OF_QUESTIONS])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(C.MAX_STEP):</span><br><span class="line">        <span class="keyword">if</span> answers[i] &gt; <span class="number">0</span>:</span><br><span class="line">            result[i][questions[i]] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> answers[i] == <span class="number">0</span>:</span><br><span class="line">            result[i][questions[i] + C.NUM_OF_QUESTIONS] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>与原文保持一致，one-hot的维度为两倍的总题目数，所以对于readata中处理好的每一条记录ques，将变成[C.MAX_STEP, 2 * C.NUM_OF_QUESTIONS]大小的矩阵，因为每条记录ques中包含C.MAX_STEP个题目，每个题目的onehot维度为2 * C.NUM_OF_QUESTIONS。</p>
<p>接着readata中的例子，ques在DKTDataSet中转变成onehot形式之后，数据的形式变成：<br>[[1 0 0 0 0 0 0 0 0 0] -&gt; 1<br>&nbsp;[0 0 0 0 0 0 1 0 0 0] -&gt; 2<br>&nbsp;[0 0 0 0 0 0 0 0 0 0] -&gt; 0<br>&nbsp;[0 0 0 0 0 0 1 0 0 0] -&gt; 2<br>&nbsp;[0 0 0 1 0 0 0 0 0 0] -&gt; 4<br>&nbsp;[1 0 0 0 0 0 0 0 0 0] -&gt; 1<br>&nbsp;…]</p>
<p><strong>dataloader</strong>：在dataloader.py中，包含一个训练数据的loader和一个测试数据的loader，分别是getTrainLoader和getTestLoader，实际上这两个loader的实现一模一样，只是去了两个不同的名字为了区分训练和测试数据，这样的方式比较冗余，后面的版本会进行优化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTrainLoader</span><span class="params">(train_data_path)</span>:</span></span><br><span class="line">    handle = DataReader(train_data_path ,C.MAX_STEP, C.NUM_OF_QUESTIONS)</span><br><span class="line">    trainques, trainans = handle.getTrainData()</span><br><span class="line">    dtrain = DKTDataSet(trainques, trainans)</span><br><span class="line">    trainLoader = Data.DataLoader(dtrain, batch_size=C.BATCH_SIZE, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> trainLoader</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTestLoader</span><span class="params">(test_data_path)</span>:</span></span><br><span class="line">    handle = DataReader(test_data_path, C.MAX_STEP, C.NUM_OF_QUESTIONS)</span><br><span class="line">    testques, testans = handle.getTestData()</span><br><span class="line">    dtest = DKTDataSet(testques, testans)</span><br><span class="line">    testLoader = Data.DataLoader(dtest, batch_size=C.BATCH_SIZE, shuffle=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> testLoader</span><br></pre></td></tr></table></figure>
<p>关于如何定义loader就不做过多介绍，关于pytorch的dataloader的相关文章有很多。</p>
<p>在dataloader.py中还有一个函数：getLoader，这个函数封装了getTrainLoader和getTestLoader，通过调用此函数直接获取训练和测试的loader。并且函数的参数是数据集的名称，根据数据集名称分别为不同的数据集构造loader。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLoader</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    trainLoaders = []</span><br><span class="line">    testLoaders = []</span><br><span class="line">    <span class="keyword">if</span> dataset == <span class="string">'assist2009'</span>:</span><br><span class="line">        trainLoader = getTrainLoader(C.Dpath + <span class="string">'/assist2009/builder_train.csv'</span>)</span><br><span class="line">        trainLoaders.append(trainLoader)</span><br><span class="line">        testLoader = getTestLoader(C.Dpath + <span class="string">'/assist2009/builder_test.csv'</span>)</span><br><span class="line">        testLoaders.append(testLoader)</span><br><span class="line">    <span class="keyword">elif</span> dataset == <span class="string">'assist2015'</span>:</span><br><span class="line">        trainLoader = getTrainLoader(C.Dpath + <span class="string">'/assist2015/assist2015_train.txt'</span>)</span><br><span class="line">        trainLoaders.append(trainLoader)</span><br><span class="line">        testLoader = getTestLoader(C.Dpath + <span class="string">'/assist2015/assist2015_test.txt'</span>)</span><br><span class="line">        testLoaders.append(testLoader)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<h4 id="模型训练与测试-evaluation"><a href="#模型训练与测试-evaluation" class="headerlink" title="模型训练与测试-evaluation"></a>模型训练与测试-evaluation</h4><p>在evaluation目录下，有两个文件，一个是eval.py文件，主要实现模型的训练和测试以及品谷的过程；另一个是run.py文件，是主程序入口。</p>
<p><img src="http://img.chsong.live/Blogs/DKT-pytorch/7.png-o" alt=""></p>
<p><strong>eval</strong>：在eval.py文件中，定义了两个函数train和test分别实现模型的训练和测试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(trainLoaders, model, optimizer, lossFunc)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(trainLoaders)):</span><br><span class="line">        model, optimizer = train_epoch(model, trainLoaders[i], optimizer, lossFunc)</span><br><span class="line">    <span class="keyword">return</span> model, optimizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(testLoaders, model)</span>:</span></span><br><span class="line">    ground_truth = torch.Tensor([])</span><br><span class="line">    prediction = torch.Tensor([])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testLoaders)):</span><br><span class="line">        pred_epoch, gold_epoch = test_epoch(model, testLoaders[i])</span><br><span class="line">        prediction = torch.cat([prediction, pred_epoch])</span><br><span class="line">        ground_truth = torch.cat([ground_truth, gold_epoch])</span><br><span class="line">    performance(ground_truth, prediction)</span><br></pre></td></tr></table></figure>
<p>而训练过程有分为很多epoch，每一个epoch的过程在train_epoch中实现。而对于测试过程，由于某些测试集可能会很大，导致内存一次存不下，所以将测试集分成多个loader，然后对于每一个loader都调用一次test_epoch，然后把所有的loader的结果合并起来。最后，所有的结果拼接起来后，通过performance函数计算模型的各个评价指标。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">    prediction = torch.cat([prediction, pred_epoch])</span><br><span class="line">    ground_truth = torch.cat([ground_truth, gold_epoch])</span><br><span class="line">performance(ground_truth, prediction)</span><br></pre></td></tr></table></figure>
<p>对于train_epoch，过程跟一般的pytorch模型训练过程一样，读取数据loader、预测、计算损失、反向传播等：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span><span class="params">(model, trainLoader, optimizer, loss_func)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm.tqdm(trainLoader, desc=<span class="string">'Training:    '</span>, mininterval=<span class="number">2</span>):</span><br><span class="line">        pred = model(batch)</span><br><span class="line">        loss = loss_func(pred, batch)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="keyword">return</span> model, optimizer</span><br></pre></td></tr></table></figure>
<p>对于test_epoch，由于知识追踪任务比较特殊，每一个时刻的输出都是预测下一个时刻答对题目的概率，因此有一些额外的处理。先上代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_epoch</span><span class="params">(model, testLoader)</span>:</span></span><br><span class="line">    gold_epoch = torch.Tensor([])</span><br><span class="line">    pred_epoch = torch.Tensor([])</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm.tqdm(testLoader, desc=<span class="string">'Testing:    '</span>, mininterval=<span class="number">2</span>):</span><br><span class="line">        pred = model(batch)</span><br><span class="line">        <span class="keyword">for</span> student <span class="keyword">in</span> range(pred.shape[<span class="number">0</span>]):</span><br><span class="line">            temp_pred = torch.Tensor([])</span><br><span class="line">            temp_gold = torch.Tensor([])</span><br><span class="line">            delta = batch[student][:,<span class="number">0</span>:C.NUM_OF_QUESTIONS] + batch[student][:,C.NUM_OF_QUESTIONS:]</span><br><span class="line">            temp = pred[student][:C.MAX_STEP - <span class="number">1</span>].mm(delta[<span class="number">1</span>:].t())</span><br><span class="line">            index = torch.LongTensor([[i <span class="keyword">for</span> i <span class="keyword">in</span> range(C.MAX_STEP - <span class="number">1</span>)]])</span><br><span class="line">            p = temp.gather(<span class="number">0</span>, index)[<span class="number">0</span>]</span><br><span class="line">            a = (((batch[student][:, <span class="number">0</span>:C.NUM_OF_QUESTIONS] - batch[student][:, C.NUM_OF_QUESTIONS:]).sum(<span class="number">1</span>) + <span class="number">1</span>)//<span class="number">2</span>)[<span class="number">1</span>:]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(p)):</span><br><span class="line">                <span class="keyword">if</span> p[i] &gt; <span class="number">0</span>:</span><br><span class="line">                    temp_pred = torch.cat([temp_pred,p[i:i+<span class="number">1</span>]])</span><br><span class="line">                    temp_gold = torch.cat([temp_gold, a[i:i+<span class="number">1</span>]])</span><br><span class="line">            pred_epoch = torch.cat([pred_epoch, temp_pred])</span><br><span class="line">            gold_epoch = torch.cat([gold_epoch, temp_gold])</span><br><span class="line">    <span class="keyword">return</span> pred_epoch, gold_epoch</span><br></pre></td></tr></table></figure>
<p>在test_epoch函数中，先定义两个列表，分别用来存储真实结果ground truth 和预测的结果pred：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gold_epoch = torch.Tensor([])</span><br><span class="line">pred_epoch = torch.Tensor([])</span><br></pre></td></tr></table></figure>
<p>然后读取数据，分多个batch进行预测，因为一次预测可能数据量过大导致内存溢出而出错。Note：每一个batch中包含多个学生，每个学生有maxstep个题目，每个题目表示成了2*num_of_ques维的onehot向量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> tqdm.tqdm(testLoader, desc=<span class="string">'Testing:    '</span>, mininterval=<span class="number">2</span>):</span><br><span class="line">    pred = model(batch)</span><br></pre></td></tr></table></figure>
<p>预测完之后，整理数据，把学生所有的题目的预测结果存储起来，方便后面的评估。对于每一个学生，先创建两个列表，分别存储真是答题结果ground truth和预测结果pred。然后再将每个学生的结果添加进开始定义的两个总结果列表gold_epoch和pred_epoch中去。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> student <span class="keyword">in</span> range(pred.shape[<span class="number">0</span>]):</span><br><span class="line">    temp_pred = torch.Tensor([])</span><br><span class="line">    temp_gold = torch.Tensor([])</span><br></pre></td></tr></table></figure>
<p>然后是获取预测结果，这里先将2*num_of_ques维的题目onehot向量分成前后两个部分，每部分分别是num_of_ques维，然后相加，乘以预测结果，即可得到对应的题目的预测结果，这里的计算过程可自行推敲，等有机会再给出可视化的计算过程。因为每一个时刻都是预测的下一个时刻的结果，所以题目编号需要向后移一个，体现在delta[1:]这里：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">delta = batch[student][:,<span class="number">0</span>:C.NUM_OF_QUESTIONS] + batch[student][:,C.NUM_OF_QUESTIONS:]</span><br><span class="line">temp = pred[student][:C.MAX_STEP - <span class="number">1</span>].mm(delta[<span class="number">1</span>:].t())</span><br><span class="line">index = torch.LongTensor([[i <span class="keyword">for</span> i <span class="keyword">in</span> range(C.MAX_STEP - <span class="number">1</span>)]])</span><br><span class="line">p = temp.gather(<span class="number">0</span>, index)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>对于答题的真实结果，其实在onehot的向量中就已经体现了，答对则向量前半部分对应的位置为1，答错则向量后半部分对应的位置为1。根据这个特点，按照下面的方式就可以直接通过onehot向量推出真实答题结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = (((batch[student][:, <span class="number">0</span>:C.NUM_OF_QUESTIONS] - batch[student][:, C.NUM_OF_QUESTIONS:]).sum(<span class="number">1</span>) + <span class="number">1</span>)//<span class="number">2</span>)[<span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
<p>到此处为止，预测结果和真实结果就已经都得到了。但是，这里还要在做一个筛选，别忘了我们之前在数据长度不够的时候是补0了的，这里需要把补0的结果全部都过滤掉。由于补零的题目的onehot向量为全零向量，那么全零向量经过神经网络之后预测结果肯定为0。而正常题目不是非零的，那么预测结果为0的可能性极小，因为神经网络参数为0的可能性极小。所以我们根据预测结果是否为0，直接把为0的全部去除掉（我们这里的处理方法似乎不是很合理，因为正常题目也是有可能出现预测结果为0的情况，但是这种可能性极小，对模型整体而言几乎没什么影响，所以这么做也是合理的，并且十分方便）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> p[i] &gt; <span class="number">0</span>:</span><br><span class="line">    temp_pred = torch.cat([temp_pred,p[i:i+<span class="number">1</span>]])</span><br><span class="line">    temp_gold = torch.cat([temp_gold, a[i:i+<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<p>在每次处理完一个学生的数据之后，将其添加到总结果列表中去：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_epoch = torch.cat([pred_epoch, temp_pred])</span><br><span class="line">gold_epoch = torch.cat([gold_epoch, temp_gold])</span><br></pre></td></tr></table></figure>
<p>最后返回结果即可。</p>
<p>在eval.py文件中还定义了一个损失函数类lossFunc，基于pytorch框架的自定义的损失函数。其实这个损失函数就是分类问题中常用的交叉熵函数，只是知识追踪问题的数据是序列化的，所以这里不太方便直接调用pytorch框架中已有的交叉熵函数，自己按需实现了一下，里面涉及的一些过程和test_epoch中的部分过程类似：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">lossFunc</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(lossFunc, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, pred, batch)</span>:</span></span><br><span class="line">        loss = torch.Tensor([<span class="number">0.0</span>])</span><br><span class="line">        <span class="keyword">for</span> student <span class="keyword">in</span> range(pred.shape[<span class="number">0</span>]):</span><br><span class="line">            delta = batch[student][:,<span class="number">0</span>:C.NUM_OF_QUESTIONS] + batch[student][:,C.NUM_OF_QUESTIONS:]</span><br><span class="line">            temp = pred[student][:C.MAX_STEP - <span class="number">1</span>].mm(delta[<span class="number">1</span>:].t())</span><br><span class="line">            index = torch.LongTensor([[i <span class="keyword">for</span> i <span class="keyword">in</span> range(C.MAX_STEP - <span class="number">1</span>)]])</span><br><span class="line">            p = temp.gather(<span class="number">0</span>, index)[<span class="number">0</span>]</span><br><span class="line">            a = (((batch[student][:, <span class="number">0</span>:C.NUM_OF_QUESTIONS] - batch[student][:, C.NUM_OF_QUESTIONS:]).sum(<span class="number">1</span>) + <span class="number">1</span>)//<span class="number">2</span>)[<span class="number">1</span>:]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(p)):</span><br><span class="line">                <span class="keyword">if</span> p[i] &gt; <span class="number">0</span>:</span><br><span class="line">                    loss = loss - (a[i]*torch.log(p[i]) + (<span class="number">1</span>-a[i])*torch.log(<span class="number">1</span>-p[i]))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<p>最后，eval.py文件中包含一个performance函数，从名字就可以看出这个函数用来评价模型的表现，也就是计算预测结果的各个指标，包括AUC、F1、Recall、Precision，可以根据需要自行添加，计算方式可自定义或者直接掉包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">performance</span><span class="params">(ground_truth, prediction)</span>:</span></span><br><span class="line">    fpr, tpr, thresholds = metrics.roc_curve(ground_truth.detach().numpy(), prediction.detach().numpy())</span><br><span class="line">    auc = metrics.auc(fpr, tpr)</span><br><span class="line">    f1 = metrics.f1_score(ground_truth.detach().numpy(), torch.round(prediction).detach().numpy())</span><br><span class="line">    recall = metrics.recall_score(ground_truth.detach().numpy(), torch.round(prediction).detach().numpy())</span><br><span class="line">    precision = metrics.precision_score(ground_truth.detach().numpy(), torch.round(prediction).detach().numpy())</span><br><span class="line">    print(<span class="string">'auc:'</span> + str(auc) + <span class="string">' f1: '</span> + str(f1) + <span class="string">' recall: '</span> + str(recall) + <span class="string">' precision: '</span> + str(precision) + <span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<p>到此处为止，DKT项目的所有部分都已介绍完毕。由于时间仓促，并没有把所有细节都介绍很清楚，但对于学习和理解DKT来说已经足够了。后续有时间会根据需要补充一些更细节的介绍，如果有什么问题或建议可直接评论留言，我会及时回复，或者通过主页的邮箱联系。</p>

<font color=red>这里有一个知识追踪前沿研究技术交流群，欢迎大家进群交流学习，群聊及更多精彩内容请关注公众号。
</font>



<div id="jd">
<img src="https://img.chsong.live/Blogs/DKT-pytorch/DKT交流群.png-m">
</div>



<script src="https://readmore.openwrite.cn/js/readmore.js" type="text/javascript"></script>
<script>
    const btw = new BTWPlugin();
    btw.init({
        id: 'jd',
        blogId: '26372-1618624976356-155',
        name: '一切皆可解读',
        qrcode: 'https://img.chsong.live/Blogs/gzh-erweima.png-o',
        keyword: '解锁',
    });
</script>


]]></content>
      <tags>
        <tag>算法</tag>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>游戏实时胜率预测</title>
    <url>/20201123_%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/index.html</url>
    <content><![CDATA[<p><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/winprob.png-o" alt=""></p>
<p>在游戏过程中进行实时胜率预测，能够为观战者、解说提供话题引导和需求。实时胜率预测系统目前 在游戏赛事的观战直播领域已经出现一些应用尝试。肯德基KI上校、DOTA PLUS胜率预测面板，已经在LOL和DOTA玩家中取得了良好的反馈。通过战斗的实时胜率预测，不仅可以制造话题为比赛带来乐趣，也可以通过事后回顾，分析对局中的得失，提升竞技实力，对游戏玩法参与感和体验，是一种革新。</p>
<a id="more"></a>

<p>本文是一个关于游戏实时胜率预测ppt的介绍，这个ppt是我在实验室一次大分享上的报告。此ppt主要包括四个部分：背景介绍、相关工作、我们的工作、以及总结。其中我们的工作，是我之前在网易实习时所作的一项研究，是关于<a href="http://n.163.com" target="_blank" rel="noopener">逆水寒</a>游戏实时胜率预测的工作。</p>
<table>
<thead>
<tr>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/1.png-m" alt=""></th>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/2.png-m" alt=""></th>
</tr>
</thead>
</table>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>首先是介绍了一下游戏背景部分，主要包括当前全球游戏市场的现状、游戏对学术界的影响、游戏在产业界的应用。然后引出实时胜率预测的应用及其重要性，最后总结实时胜率预测及其相关的延伸问题。</p>
<table>
<thead>
<tr>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/3.png-m" alt=""></th>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/4.png-m" alt=""></th>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/5.png-m" alt=""></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/6.png-m" alt=""></td>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/7.png-m" alt=""></td>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/8.png-m" alt=""></td>
</tr>
</tbody></table>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>然后是相关工作部分，从两个方面来介绍。一方面是简要回顾了一下传统的统计学方法比如BT算法、ELo机制等。另一方面是介绍基于深度学习的方法。挑了三个比较有代表性的研究进行相对详细的介绍，一个是基于英雄联盟游戏视频的高光时刻生成、一个是基于王者荣耀游戏视频的无监督高光片段检测框架、另一个是足球运动员动作价值评估。</p>
<table>
<thead>
<tr>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/9.png-m" alt=""></th>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/10.png-m" alt=""></th>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/11.png-m" alt=""></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/12.png-m" alt=""></td>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/13.png-m" alt=""></td>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/14.png-m" alt=""></td>
</tr>
<tr>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/15.png-m" alt=""></td>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/16.png-m" alt=""></td>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/17.png-m" alt=""></td>
</tr>
</tbody></table>
<h2 id="我们的工作"><a href="#我们的工作" class="headerlink" title="我们的工作"></a>我们的工作</h2><p>我们的工作主要是基于逆水寒游戏数据，研究实时胜率预测模型。所作的工作主要包括三个步骤，首先基于shapely value对数据进行了分析，分析游戏中不同角色的数量对游戏结果的影响；然后采用LR、XGboost等方法进行实时胜率预测实验，效果挺好，但是可解释性不足。后来将数据处理成图片形式，还原游戏对局原貌，采用CNN实现胜率预测，并通过热力图提供强解释性。</p>
<table>
<thead>
<tr>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/18.png-m" alt=""></th>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/19.png-m" alt=""></th>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/20.png-m" alt=""></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/21.png-m" alt=""></td>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/22.png-m" alt=""></td>
<td align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/23.png-m" alt=""></td>
</tr>
</tbody></table>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后总结了一下基于游戏实时胜率预测的可能的研究方向，主要包括：关键点识别、高光时刻检测、实时胜率的可解释性、战报自动生成、战场数据表征等。</p>
<table>
<thead>
<tr>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/24.png-m" alt=""></th>
<th align="center"><img src="https://img.chsong.live/Blogs/%E6%B8%B8%E6%88%8F%E5%AE%9E%E6%97%B6%E8%83%9C%E7%8E%87%E9%A2%84%E6%B5%8B/25.png-m" alt=""></th>
</tr>
</thead>
</table>
<p>获取完整ppt，搜索关注微信公众号【一切皆可解读】，回复关键词【XZ001】直接下载。<br><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>智能化教育与隐私保护</title>
    <url>/20201123_%E6%99%BA%E8%83%BD%E5%8C%96%E6%95%99%E8%82%B2%E4%B8%8E%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4/index.html</url>
    <content><![CDATA[<p><img src="https://imgs.ebrun.com/resources/2018_01/2018_01_09/2018010914915154810164470.jpg" alt=""></p>
<p>人工智能不仅是一场技术革命和产业革命，更是一场数据革命。为了不断提升智能化水平，必定有越来越多的数据被收集。<a id="more"></a>在智能教育领域，学习者等相关的主体都已被卷入这场声势浩大的数据革命之中。如何在发展智能教育的同时，实现对学习者数据在存储、共享、使用过程中隐私的保护，必定会成为智能教育时代的主题。目前，智能教育和隐私保护之间的平衡性仍处于基础设想阶段。本人及课题组基于教育领域的数据特征，结合隐私保护相关法律法规、伦理道德，界定不同的隐私及隐私程度；从智能教育实施的整个流程所涉及的数据采集、存储与传输、共享与使用等环节来分析隐私泄露的可能性，同时研究具体的实现隐私保护的相关技术。研究结果对于合理发挥教育数据的价值进而提升智能教育水平具有重要意义；为教育的公平性、相关立法、教育领域大数据防火墙的构筑等提供了新的指导。</p>
<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>再见</title>
    <url>/20201103_%E5%86%8D%E8%A7%81/index.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">您好, 这里需要密码.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="bf66d1a238f8c7953e6e7753a591a33d504129fd40acffdf0bc8eba7b8cff824">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <tags>
        <tag>随笔</tag>
        <tag>动态</tag>
      </tags>
  </entry>
  <entry>
    <title>牛客-公平划分</title>
    <url>/20200712_%E5%85%AC%E5%B9%B3%E5%88%92%E5%88%86/index.html</url>
    <content><![CDATA[<p>牛客网系统上的测试用例经常有问题，比如这一题，输入数据有问题。一般情况下，代码完全正确只能通过80%的case。必须对有问题的输入针对性处理才能通过。</p>
<a id="more"></a>

<h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>小爱和小溪有N个数字，他们两个想公平的分配这些数字。小爱拿的数字集合为$I = [i_1, i_2, i_K]$，小溪获得剩下的$J=[j_1, j_2, j_{N-K} ]$。但是他们衡量分配公平与否的原则与众不同:<br>$$<br>f(I) = \sum_{i\in I}\sum_{j\in J}|a_i-a_j|<br>$$<br>在小爱拿到其中的K个数字的前提下，计算出他们分配偏差$f(I)$的最小值。</p>
<h2 id="输入描述"><a href="#输入描述" class="headerlink" title="输入描述"></a>输入描述</h2><blockquote>
<p>输入第一行两个数字，分别表示总的数字量N和小爱拿的数字量K。第二行有N个数字，表示每个数字的值。</p>
</blockquote>
<h2 id="输出描述"><a href="#输出描述" class="headerlink" title="输出描述"></a>输出描述</h2><blockquote>
<p>输出一个数字，表示分配偏差f(I)的最小值。</p>
</blockquote>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>输入</p>
<blockquote>
<p>4 1</p>
<p>3 3 3 1</p>
</blockquote>
<p>输出</p>
<blockquote>
<p>2</p>
</blockquote>
<h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><p>牛客官网给的提示是 <strong>动态规划</strong>和<strong>穷举</strong>，我没有想出动态规划的方案，这里用<strong>穷举</strong>的方式可以通过。</p>
<p>对于给定的N个数，小爱同学拿了其中的K个数，那么也就是从N个数中取出K个数，共有$\tbinom{N}{K}$种情况。遍历这$\tbinom{N}{K}$种情况，得到最小的$f(I)$即为最后的答案。</p>
<p>那么问题就转化成了求N个数中取K个数的所有组合情况，本题用combination(data, r)函数，data为list类型数据，r表示从data中取出r个数。combination函数能够返回所有的r个数的组合。关于组合函数combination(data, r)的详解可以看文章<strong>列表排列组合</strong>（撰写中…）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combination</span><span class="params">(data, r)</span>:</span></span><br><span class="line">    n = len(data)</span><br><span class="line">    index = list(range(r))</span><br><span class="line">    <span class="keyword">yield</span> set(index)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> reversed(range(r)):</span><br><span class="line">            <span class="keyword">if</span> index[i] &lt; n - r + i:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        index[i] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, r):</span><br><span class="line">            index[j] = index[j<span class="number">-1</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">yield</span> set(index)</span><br></pre></td></tr></table></figure>

<p>首先，获得小爱同学的K个数的所有情况sets1 = combination(data, K)，这里combination返回的是python中的生成器，需要通过如下形式迭代形式访问每一种情况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> set1 <span class="keyword">in</span> sets1:</span><br><span class="line">	...</span><br></pre></td></tr></table></figure>

<p>这里每一个set1就表示小爱同学的一种取K个数的情况，那么用所有的N个数剔除set1中的数，剩余的数构成set2就是小溪同学的N-K个数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">set2 = set(range(N)) - set1</span><br></pre></td></tr></table></figure>

<p>然后求分配偏差</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bias = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> set1:</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> set2:</span><br><span class="line">		bias += abs(data[i] - data[j])</span><br></pre></td></tr></table></figure>

<p>判断是否比当前的最小偏差小</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">min_bias = min(min_bias, bias)</span><br></pre></td></tr></table></figure>

<p>最后输出min_bias。</p>
<h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combination</span><span class="params">(data, r)</span>:</span></span><br><span class="line">    n = len(data)</span><br><span class="line">    index = list(range(r))</span><br><span class="line">    <span class="keyword">yield</span> set(index)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> reversed(range(r)):</span><br><span class="line">            <span class="keyword">if</span> index[i] &lt; n - r + i:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        index[i] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, r):</span><br><span class="line">            index[j] = index[j<span class="number">-1</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">yield</span> set(index)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">########## N, K 输入 ############</span></span><br><span class="line">    line1 = input().strip(<span class="string">''</span>).split(<span class="string">' '</span>)</span><br><span class="line">    N, K = int(line1[<span class="number">0</span>]), int(line1[<span class="number">1</span>])</span><br><span class="line">    <span class="comment">################################</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> N &lt;= <span class="number">0</span> <span class="keyword">or</span> K &lt;= <span class="number">0</span>:</span><br><span class="line">        print(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    line2 = input().strip(<span class="string">''</span>).split(<span class="string">' '</span>)</span><br><span class="line">    data = [int(e) <span class="keyword">for</span> e <span class="keyword">in</span> line2]</span><br><span class="line">    </span><br><span class="line">    min_bias = sys.maxsize</span><br><span class="line">    </span><br><span class="line">    sets1 = combination(data, K)</span><br><span class="line">    <span class="keyword">for</span> set1 <span class="keyword">in</span> sets1:</span><br><span class="line">        set2 = set(range(N)) - set1</span><br><span class="line">        bias = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> set1:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> set2:</span><br><span class="line">                bias += abs(data[i] - data[j])</span><br><span class="line">        min_bias = min(min_bias, bias)</span><br><span class="line">    print(min_bias)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>正常情况下，上述代码是完全正确的。可是有的测试用例有问题，N和K应改是同一行输入的，有的测试用例N和K分两行输入。</p>
<p><strong>正常测试用例：</strong></p>
<blockquote>
<p>N, K</p>
<p>d1 d2 d3 … dN</p>
</blockquote>
<p><strong>异常测试用例：</strong></p>
<blockquote>
<p>N</p>
<p>K</p>
<p>d1 d2 d3 … dN</p>
</blockquote>
<p>因此，如果要提交通过的话，需要将上面N，K输入部分，替换成面的代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dim = list(map(int, input().split()))</span><br><span class="line"><span class="keyword">if</span> len(dim) == <span class="number">2</span>:</span><br><span class="line">	N = dim[<span class="number">0</span>]</span><br><span class="line">	K = dim[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	N = dim[<span class="number">0</span>]</span><br><span class="line">	K = int(input())</span><br></pre></td></tr></table></figure>

<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>算法</tag>
        <tag>牛客网</tag>
      </tags>
  </entry>
  <entry>
    <title>牛客-商品交易</title>
    <url>/20200710_%E5%95%86%E5%93%81%E4%BA%A4%E6%98%93/index.html</url>
    <content><![CDATA[<p>这题在牛客网上标签有<strong>动态规划</strong>和<strong>贪心</strong>，因此，用可以用动态规划和贪心两种算法来解决。</p>
<a id="more"></a>

<h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>珐达采下个月要去鸥洲各国考察一趟，采购流通神秘石并从中搞点油水。<br>珐达采会按顺序依次经过序号分别为$1, 2, 3, …, n$的鸥洲国家，在第i个国家神秘石的流通价格为$A_i$鸥。因为行程紧张，在每个国家的停留时间有限，所以他只能花费$A_i$鸥买入一块神秘石，或者卖出一块手中的神秘石获得$A_i$鸥，或者什么都不做，而且因为神秘石的保存需要极其先进的高级材料容器，其材料稀有且制作困难，珐达采只有一份容器，故无论何时珐达采手里 最多只能拥有一块神秘石。<br>珐达采想知道最终能从中获利最大多少鸥。因为交易需要手续费，所以珐达采还想知道在获利最大收益的同时，最少需要交易多少次。因为珐达采是大财阀，所以你可以认为他一开始金钱无限。</p>
<h2 id="输入描述"><a href="#输入描述" class="headerlink" title="输入描述"></a>输入描述</h2><blockquote>
<p>第一行一个数$n$。$1\le n \le 100000$</p>
<p>第二行n$n$数，第$i$个数表示$A_i$。$1\le A_i \le 1e9$</p>
</blockquote>
<h2 id="输出描述"><a href="#输出描述" class="headerlink" title="输出描述"></a>输出描述</h2><blockquote>
<p>共一行，两个数，分别代表最大收益和对应的最少交易次数。</p>
</blockquote>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>s输入</p>
<blockquote>
<p>5<br>9 7 10 1 5</p>
</blockquote>
<p>输出</p>
<blockquote>
<p>7 4</p>
</blockquote>
<h2 id="方法分析"><a href="#方法分析" class="headerlink" title="方法分析"></a>方法分析</h2><p>初步分析后，此题的意思就是，给定$N$个数，按顺序依次经过这$N$个数，当处于第$i$个数的时候，可以以第$i$个数为价格买进或者卖出宝石，有一个限制条件就是手里最多只能买进1个宝石。</p>
<h3 id="暴力穷举"><a href="#暴力穷举" class="headerlink" title="暴力穷举"></a>暴力穷举</h3><p>那么每经过一个数的时候，有且只有三种操作：1-买宝石，2-卖宝石，3-不买也不卖。定义从第一个数到最后一个数，对每一个数所作的操作构成的序列称为一个操作序列。因此，给定N个数，最多有$3^N$个操作序列，当然其中肯定有不合理的序列（简便起见，不作过多解释），那么用暴力穷举的算法，时间复杂度接近于$O(3^N)$。</p>
<h3 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h3><p>动态规划算法最核心的要素有两点：<strong>状态；状态转移方程；</strong><br>状态选取的好坏有时候可以决定这个问题能否被解决。一般状态的选取要满足两个条件：<br><strong>1. 最优子结构</strong><br><strong>子结构</strong>：子结构指的是，一个问题可以分解为多个多个子问题，每一个子问题就称为一个子结构，而子问题又能分解为更小的子问题，形成更小的子结构。<br><strong>最优子结构</strong>：每一个问题或子问题的最优值，都能够有各自的子问题的最优解推导而来。而每一个子问题的最优解即为<strong>状态</strong>。<br><strong>2. 无后效性</strong><br><strong>无后效性</strong>：无后效性指的是，我们只关心每一个子问题的最优值<strong>是多少</strong>，而不关心这个最优值是<strong>怎么来的</strong>。换句话说就是，无论当前这个子问题的最优值是采用什么方法怎么得到的，都不影响后续问题（当前子问题的父问题）最优值的求解。</p>
<p>对于本题，给定$n$个数$[a_1,a_2, \dots, a_{n-1}, a_n]$目标是求顺序经过这$n$个数后的最大收益。子问题可以定义成：求顺序经过$[a_1, a_2, \dots, a_{n-1}]$这$n-1$个数的最大收益，然后再决定在第$n$个数的时候采取哪种操作，是<strong>买</strong>、<strong>卖</strong>还是<strong>不买也不卖</strong>来判断原问题的最优值。</p>
<p>首先，这里我们定义子问题【求顺序经过$[a_1,a_2, \dots, a_{i}]$这$i$个数的最大收益】的解也就是状态，为<strong>dp[i]</strong>。</p>
<p>然后，在第$i+1$个数的时候，判断采取哪种操作，得到子问题【求顺序经过$[a_1,a_2, \dots, a_{i+1}]$这$i+1$个数的最大收益】的最优值<strong>dp[i+1]</strong>。<br>这样似乎很好，可是在知道了<strong>dp[i]</strong>之后，却不知道经过$i$个数后手里有没有宝石，那么在判断第$i+1$个数采取哪种操作的时候就没有判断依据，因为都不知道到了手里还有没有宝石。<br>那么我们可以引入一个参数<strong>own</strong>(取值True或False)指示手里有没有宝石，如果宝石被卖掉则own置为False，如果买进则置为True，否则不改变own的值。</p>
<p>以上过程似乎很合理，可是当我们在决策第$i+1$个数的时候，我们只能知道own是True或者False其中一种情况。换句话说，如果此时own为False，那我们就知道第$i$个数决策后手里没有宝石，此时我们会在第$i+1$个数上决策到底买还是不买。可是我们不知道如果own为True，也就是第$i$个数决策后手里有宝石的情况。你可能会说，既然own为False了，那么肯定own为False是第$i$个数的最佳决策结果，很正确。可是存在一种情况就是，我在第$i$个数的时候拥有宝石，也就是own为True（买进或者不卖）虽然比不拥有宝石的收益小，但有可能我在后面卖掉获得的收益会超过当前own为False的收益。</p>
<p>所以我们要对比有或没有宝石两种情况，在任何一个中间数$i$上，我们要求出有宝石的最大收益和没有宝石的最大收益。两者虽然不等，但后面有可能有宝石的超越没宝石的，或者相反。最终的结果要到最后一个数的时候才知道。因此我们要同时记录有宝石和没宝石两种情况。因此我们将<strong>d[i]</strong>扩展为<strong>d[0][i]</strong>和<strong>d[1][i]</strong>，前者表示在第$i$个数决策完之后手上没有宝石的收益，后者表示在第$i$个数决策完之后手上有宝石的收益。</p>
<p>对于<strong>d[0][i]</strong>，在第$i$个数决策完之后手上没有宝石，有两种情况。一种是在第$i-1$决策完之后手上本来就没有宝石，那么为了保持在第$i$个时刻没宝石，就不能买进，所以<strong>d[0][i]</strong>的收益就是<strong>d[0][i-1]</strong>；另一种是在第$i-1$决策完之后手上有宝石，那么为了保持在第$i$个时刻没宝石，就必须在第$i$个时刻卖掉，所以<strong>d[0][i]</strong>的收益就是<strong>d[1][i-1]</strong> + a[i]。这里的a[i]是宝石在第$i$个数上的价格。为了使得<strong>d[0][i]</strong>最大，所以求一下两者之间的最大值：<br>$$<br>d[0][i] = max(d[0][i-1], d[1][i-1] + a[i])<br>$$</p>
<p>对于<strong>d[1][i]</strong>，在第$i$个数决策完之后手上有宝石，也有两种情况。一种是$i-1$时刻没有宝石，另一种是有宝石。分析同上，试着分析一下。最后可以得到：<br>$$<br>d[1][i] = max(d[1][i-1], d[0][i-1] - a[i])<br>$$<br>第二个公式为什么是减去a[i]？仔细想一下。</p>
<p>到此为止，我们即可得到动态规划要求的每一个时刻的状态d[0][i]和d[1][i]，以及状态转移方程：<br>$$<br>d[0][i] = max(d[0][i-1], d[1][i-1] + a[i])\\<br>d[1][i] = max(d[1][i-1], d[0][i-1] - a[i])<br>$$</p>
<p>根据状态转移方程即可得到动态规划核心代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">	d[<span class="number">0</span>][i] = max(d[<span class="number">0</span>][i<span class="number">-1</span>], d[<span class="number">1</span>][i<span class="number">-1</span>] + a[i])</span><br><span class="line">	d[<span class="number">1</span>][i] = max(d[<span class="number">1</span>][i<span class="number">-1</span>], d[<span class="number">0</span>][i<span class="number">-1</span>] - a[i])</span><br><span class="line"><span class="comment"># 最后返回有宝石和没宝石两种情况的最大值</span></span><br><span class="line"><span class="keyword">return</span> max(d[<span class="number">0</span>][n], d[<span class="number">1</span>][n])</span><br></pre></td></tr></table></figure>
<p>待续…</p>
<h3 id="贪心策略"><a href="#贪心策略" class="headerlink" title="贪心策略"></a>贪心策略</h3><p>待续…</p>
<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>算法</tag>
        <tag>牛客网</tag>
      </tags>
  </entry>
  <entry>
    <title>参加CIKM会议</title>
    <url>/20191107_CIKM/index.html</url>
    <content><![CDATA[<p>第一次参加国际会议，初来乍到</p>
<p>太难了，紧张得不要不要的</p>
<p>报告前8小时，手机摔坏了</p>
<a id="more"></a>


<p><img src="https://img.chsong.live/CIKM-2019/IMG20191104082446.jpg?x-oss-process=style/m" alt="lG3sr8.jpg"></p>
<h2 id="Presentation"><a href="#Presentation" class="headerlink" title="Presentation"></a>Presentation</h2><p>主持人能不能别催，挺醒我: “one minute，one minute”</p>
<p>我: “OK” （此时实验才讲一半）</p>
<p>我: “since the limitation of the time, we skip the case study” （有点紧张随口说的，不知道有没有语法错误）</p>
<p>预先准备时正常读完备注需要8分钟，要在7分钟讲完，还得时不时看看大屏幕和观众以免僵硬，好难呀</p>
<p>还是ppt的内容放多了，之前没舍得删掉</p>
<p>那个提问的小姐姐，声音小了点啊，主持人真是的，也不给个话筒</p>
<p>我瞎扯一通不知道合不合你的问题</p>
<p><img src="https://img.chsong.live/CIKM-2019/lGBuIP.jpg?x-oss-process=style/m" alt="lGBuIP.jpg"></p>
<h2 id="Poster-Session"><a href="#Poster-Session" class="headerlink" title="Poster Session"></a>Poster Session</h2><p>开始我和左右两边的两个外国大兄弟，还没有人来找我们交流，我们就聊了聊，互相介绍工作</p>
<p>一个爱尔兰的，一个加拿大的</p>
<p>让我说还行，听是真的有点头疼，能知道你做的啥东西，专业词组听不懂，实在不知道细节</p>
<p>emmmm，可是还得保持微笑，还附和着：“Yeah, Yeah, Good”</p>
<p>叫Felix的大兄弟，走的时候给我来一句中文：“很高兴认识你”</p>
<p>我：”what? what?”</p>
<p>你可以直接说nice to meet you, 这我还是能听懂的</p>
<p><img src="https://img.chsong.live/CIKM-2019/lGB956.jpg?x-oss-process=style/m" alt="lGB956.jpg"></p>
<h2 id="Banquet"><a href="#Banquet" class="headerlink" title="Banquet"></a>Banquet</h2><p>小吃有糖葫芦，糖人，吹糖人</p>
<p>糖葫芦味道挺棒虽然有点酸</p>
<p>师兄们不要笑，糖葫芦挺好吃的，咋不来尝尝呢</p>
<p>还有武术，舞狮，戏剧，大鱼海棠，满满的中国风</p>
<p>从提出idea到今天，整个过程难呀，感谢师兄师姐，还有导师们的帮助</p>
<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>动态</tag>
      </tags>
  </entry>
  <entry>
    <title>保研夏令营经验总结</title>
    <url>/20190428_SummerCamp/index.html</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>从关注夏令营到夏令营结束，花了好长的时间，这学期的课也没有选多少就是为了准备夏令营，参加了四个夏令营，“”旅游“将近二十天，天天在外面跑晒黑了不少（今年气温贼高，大多40度以上）。7月4号到7月6号参加北京大学前沿交叉学科研究院（以下称“叉院”）的夏令营，7月7号都7月9号参加清华大学计算机学院的夏令营，7月13号到7月16号参加南京大学计算机学院夏令营，最后一个7月17号到7月23号参加中国科学技术大学计算机学院夏令营。最终中科大offer确定！</p>
<a id="more"></a>

<p>我的个人基本情况：</p>
<blockquote>
<p>专业：软件工程<br>学分绩排名：8/235<br>英语四六级：526，490<br>数模美赛一等，数学竞赛全国二等和省一等，节能减排全国三等，还有一些校级一二三等奖</p>
</blockquote>
<h2 id="关注夏令营"><a href="#关注夏令营" class="headerlink" title="关注夏令营"></a>关注夏令营</h2><p>对于关注夏令营的问题，我觉得宜早不宜迟，越早心里越有准备。之前听说过不知道哪个学校的一个学姐到九月份了都还不知道有保研夏令营这么一回事^~^，最后还是走的九月正式推免这条路，还是早点了解为好，建议在大三下学期开始就着手。<br>这里有一些有用的网站以及app：</p>
<ul>
<li>保研论坛：<a href="http://www.eeban.com/" target="_blank" rel="noopener">www.eeban.com</a></li>
<li>导师信息网：<a href="https://www.mysupervisor.org/" target="_blank" rel="noopener">www.mysupervisor.org</a></li>
<li>保研通APP：<a href="http://www.973.com/xiazai/60337" target="_blank" rel="noopener">www.973.com/xiazai/60337</a></li>
<li>保研论坛APP：<a href="https://www.7down.com/soft/175489.html" target="_blank" rel="noopener">www.7down.com/soft/175489.h…</a></li>
</ul>
<h2 id="准备材料-amp-联系导师"><a href="#准备材料-amp-联系导师" class="headerlink" title="准备材料&amp;联系导师"></a>准备材料&amp;联系导师</h2><p>最重要的是准备成绩单和排名证明（前五学期），当时排名刚出来我就拉上隔壁班一个喜欢扯淡的邱同学一起去教务处打印成绩单和排名证明，我们学院教务处还好，不怼人，也不会以各种理由要留住你而不给你打印，我们貌似是最早的，还是那句话宜早不宜迟。打印出来之后最好拿复印店去彩印几份。<br>最麻烦也是最尴尬的一件事就是去找各个老师给你在推荐信上签字，推荐信自己电子版写好打印出来，然后找老师签字，因为我们学院的教授副教授就那么几个还是算上院长副院长，而要报的学校又那么多，么个学校大概在两到三封，多次找同一个老师会非常尴尬，邱某就是找了老师签了好几次，最后写错了一个地方又去找老师签字，老师当场怼他：”你到底要报多少个呀“。我也是，我去找院长签字的时候说“我记得给你签过，你报了多少啊，别到时报了又不去坏了西工大名声”，真是非常尴尬。建议最好是将所有的推荐信都准备好，需要某一个老师签的所有信一次拿过去给他让他签了，然后再去找其他老师。<br>  除了上述材料麻烦之外，剩余的就简单了，就剩个人简历，个人陈述，获奖证书复印件等，差不多就这些了，之后就开始联系导师了，我大概是在4，5月份开始联系老师，联系的方式是电子邮件，主页中写上自己的一些情况，例如教育背景，竞赛和项目经历，感兴趣方向以及未来规划等，最后在附件中附上简历，成绩单和排名证明足矣！我联系了很多，现在回去看看邮箱，来往信件共100多封。发邮件要广发你的目标学校和感兴趣方向的老师，但是一个实验室和课题的老师最多只发一个，否则有可能这个实验室或课题组的老师都不会要你。但是如果老师3到5天还没回一般是对你不感兴趣，你可以再次发邮件询问，或者换老师。</p>
<h2 id="报名-amp-等待入营通知"><a href="#报名-amp-等待入营通知" class="headerlink" title="报名&amp;等待入营通知"></a>报名&amp;等待入营通知</h2><p>我当时报名时的原则是”广撒网“，当然是要比本校更好的学校，不然保出去干啥。我报了好几个学校，有的入营了，有的被刷了，有的争取到机会入营：</p>
<ul>
<li>复旦大学&amp;中国人民大学：报名报了一半放弃了，因为了解到这两所学校在工科方面不是那么出众</li>
<li>北京航空航天大学：（吐槽）北航没有网上报名系统，只是通知邮寄材料，我用EMS邮寄过去，最后收寄结果显示的是一个不知道的地方收的，我打电话给快递员他说这个地方就是向北航送快递的，我以为是的，最后入营结果出来，我和邱同学都没有录取，而是好几个（并不是说他们不好）排名在我们后面并且竞赛也比一定比我们多的同学入营了，邱同学打电话过去问，那边说是核查之后没有收我们材料的记录，也就是我们的材料没有寄过去，那边还说”焉知非福，九月在来吧”。（fuck我不知道是EMS不靠谱还是北航把这不当回事）瞬间对北航没有什么意愿了，不去拉倒。</li>
<li>清华大学：准备好材料之后就寄过去了，网上也能看到状态，比北航好多了，最后入营结果快6月底才出，有点慢，但是最后看到名单里有我，还是非常高兴的，毕竟我们专业只有两个人进了。100多人入营，比例大概15%左右。</li>
<li>北大叉院：在等到入营结果出来之后，我没有收到邮件，也就是被刷了，但是我又打电话去问那边说已经确定了，如果有补录会考虑我，最后真的有人学校考试冲突去不了有补录，然后我就去了。机会都是争取来的，给学校那边打电话多问问。这是在刷了之后还有的最后一线希望。</li>
<li>上海交通大学：感觉上交有点傲娇，入营感觉很有难度，我们专业只有第一名入营了（他最后没去），而且听说给外校的学术型硕士名额极少，基本只要直博生，我们专业好像好几个确定去直博。</li>
<li>南京大学：网上报名之后，一段时间之后发邮件通知说通过筛选了，需要网上确认入营然后邮寄材料。</li>
<li>北大信科：结果出来的最晚的一个，最后被刷了，听人说是那边看到清华名的单了入营清华的都不要（不全是，除非你特别厉害）我们专业只有第五名的同学入营。</li>
<li>中国科学技术大学：不需要邮寄材料，全部扫描成电子版在网上提交，最后我们专业就我入营，好像是1200多人中筛选了120左右的人，大概10%的入营比例。</li>
</ul>
<h2 id="夏令营汇总"><a href="#夏令营汇总" class="headerlink" title="夏令营汇总"></a>夏令营汇总</h2><p>夏令营从7月3号正式开始了。</p>
<h3 id="北大叉院夏令营"><a href="#北大叉院夏令营" class="headerlink" title="北大叉院夏令营"></a>北大叉院夏令营</h3><p>北大叉院夏令营开始最早，7月3号晚上坐火车去北京（第一次去北京），第二天大概早上8点多就到了，在火车上的时候还和之前联系的一个叉院老师邮件沟通了一下，他让我加他微信方便联系，感觉是个好的开始。从火车站坐公交到北大之后先去报道，教务处说下午两点再来。目前时间大概在10点左右，那个老师又打电话来了，问我到了没有，现在有没有时间去和他见个面，我来的比较匆忙，现在肯定不是最好的时候，我就说我刚到火车站，要不下午去见面，然后就定在了下午一点。我赶紧先到学校外面找了个饭馆吃了个饭（不知道算早饭还是午饭），然后在北大的校园里一个角落里坐了一会儿，那天真是热呀，真受不了，还好我电脑包里面有一个把扇子。大概12点40左右就去老师门口等着，他还没来，期间他的一个学生看我在等老师，他就打电话给老师说我到了，一会儿老师就来了，我们在他办公室坐下，我们面对面坐着，简单的客套了一下就转入正题了，他说问我几个问题，他问我当x很小的时候sinx大于什么东西，我印象中是在x趋于0时sinx &gt; x,我就回答了x，然后他看我回答挺快的就问为什么，说实话这个问题换做谁闭着眼睛都能答出来，我当时可能紧张了竟然忘了，扯到了x趋于0是x/sinx的极限是1，他问然后了，我知道不对，但是真的突然忘了，我就赶紧换其他方法，我说用几何方法吧，单位圆来证明，确实解决了。老师说嗯问题确实解决了，但这不是我想要的答案，我本来是想要你用微分的角度来解决的，不过你能想其他办法解决这个问题还可以吧。（结束之后想到直接是x-sinx然后求导证明单调就完事了，当时真的突然记不起来）然后下一个问题问我一个统计的问题，说如何从统计的角度求解pi的值，这个问题太简单了，高中生都会，我很快就答出来了，然后让说你之前是不是接触过这个问题，回答这么快。（不应该回答这么快，让老师觉得你接触过这个问题，现在你即使答上来也看不出你的水平，应该装着思考一下）。然后说我在问你一个问题吧，还是统计方面的，说如何知道100个人的平均分数，而且又不想把每个人的分数看一遍，我想了一会儿说随机抽样吧，他嗯了一下表情和奇怪，我不知道对还是错，他也没说对错（后来问别人，都说是抽样，我现在都不知道对还是错，他表情真的很奇怪），然后他就这个问题延伸又问我一个问你，我没听明白，他又说了半天我还是没听明白，尴尬了，我问题都没听懂咋回答。就一直在那跟他扯，他估计认为我不会就说了答案然后还给我解释，到现在我还是不明白他要问什么！！！然后他说我在问你一个问题吧，说这是他当时读博士的时候他导师面试他的问题，现在问问我，说给你一个半正定对称矩阵<strong>A</strong>，求矩阵<strong>A</strong>的n次方，或者换句话说在n很大的时候会发生什么，说实话这个问题我当时真不会，想了好久，他说给我提示就是把矩阵<strong>A</strong>分解，然后再求解，我说三角分解，表情一愣（感觉不对）说然后呢，我说不下去，我也不知道了，感觉越分解越乱啊，我们就只学了三角分解，然后我有想了半天，他知道我不会就说是矩阵的奇异值分解，我一愣说我不知道这个呀，我们就没学过这个分解，答案是很简单，但是我根本就不知道这个分解呀，可能是线性代数没学好吧。。。然后又客套了一下就结束了。哎，不会就是不会，他才不管你学没学过，平时还是应该多积累，多深入，不能只停留在老师讲的那些东西上。然后下去报道，领衣服，回宾馆休息。晚上去参加开营仪式，在一个大的报告厅，里面非常的豪华（无法形容），开营仪式上各个方向都有代表老师上来做介绍，大概半个小时到一个小时的时间就结束了，第二天就是听各个老师的报告会，各个老师上去把自己的方向吹一吹来吸引学生，下午大概3点左右有笔试，我们方向是笔试和机试可以选机试和笔试或者只选机试，机试必选，统计学方向是笔试必选，机试自愿。笔试这段时间我回去准备晚上的机试了，晚上的机试一共10道题，只要平时认真写过代码的做3道题以上没问题。我当时做了5题，然后第六和第七题一个是最短路路径问题一个是深度搜索，这两个我都能做出来，我先做的最短路问题，代码写完了但是这题提交就是通过不了，英文题目读了好几遍觉得没问题但就是过不了，结果这最后的一小时都耗在这题上，最后这两题都没做出来，后来发现是一个英文单词理解错了导致题意弄错了，其实只要代码稍微修改一下就可以了，但是题目意思弄错了真的没办法，英语水平还得好好提高。看到实时排名我做了5道题排25名，共七八十人吧，还能接受吧，我认识的我们学校的和我在内一共三个人，我做的最多，一个4题还有一个3题。机试完感觉一般吧，回去好好睡觉第三天准备面试。晚上的时候面试安排出来了，我在下一点左右，其实我们那组面试很快，老师们下午就在原地吃饭，吃完第二个就到我了，我进去之后老师先让我自我介绍，我忘记有没有要求英文，但我自我介绍是说的英文（准备好的），完了老师就开始看着材料问问题，简单说了一下竞赛，项目，我有一个软件测试竞赛省特等奖，问我为甚能得特等奖，能不能拿来创业，我就说我做的还不错，把学的知识运用的比较好而已，创业还达不到这个水平，然后就没有然后了。共四个老师，中间靠左的那个问我一个复变函数的问题，后来又有一个老师问我信号与系统的问题（因为看我成绩单上有这门课），之前我都是准备的机器学习方面的东西，比如线性代数，概率统计，数学分析，机器学习，谁会去复习信号与系统啊，我们专业选机器学习方向有谁回去看那本600多页的大厚书，的有我一直在凭着印象来说，结果肯定是不理想，然后就结束了，感觉整个过程都很不爽，没有一个问题和我准备的沾边的，后来了解了一下别人的情况，不都是这种问题，看来还得有一定的运气，充分的准备和一定的好运气才有好结果。然后就是回去等结果，收到邮件就录取了，没收到就是被刷了，很遗憾我被刷了。我们学院的第一名和我两个人都没有录取。</p>
<h3 id="清华计算机夏令营"><a href="#清华计算机夏令营" class="headerlink" title="清华计算机夏令营"></a>清华计算机夏令营</h3><p>7月7号到清华大学去报道之后再宿舍休息了一会儿，晚上就直接是机试，这次机试一共三道题，三道题基本上都是模拟类型的题目，第一题是给你一个矩阵然后输入不同指令对矩阵进行反转等各种操作，第二题是让你输入一段代码然后将代码中注释去掉然后再输出，第三题记不太清了。我做完了第一道和第三道，第二道不太会（字符串处理是硬伤）。这两道题通过自定义测试应该是没问题的，但是去清华的好多都是ACM大牛，做不出三道基本没戏，清华的一个政策是夏令营是没有面试的，不录取任何人的，机试前50名九月份直接获得面试资格，没进前50的如果能够找到老师九月推荐你面试你也可以直接获得资格，每个老师最多推荐三个，也就是说只有上面两种方法你能9月份去面试，否则你再次报名会和九月报名的人一起筛选，不一定会轮得到你，所以夏令营做好机试或者找好老师推荐很重要。我开始还以为机试做的不错，可是牛的人很多，不全做出来基本没戏，然后我就去找之前联系的老师，问问他能不能推荐我九月份来面试，还好老师答应了。但是自己感觉没有前50名那么稳，毕竟人家的机试成绩在那里。只能说九月试试运气，不能抱太大希望。<br>第二天就是听各个老师的报告会，个人都来吹一下自己的方向多么多么好多么多么有前途。一整天都是，有点无聊。<br>第三天就是最后的师生交流，每个老师都在外面摆一个牌子，感兴趣的直接去找老师交流，了解情况，其实这个时间就是用来给你联系老师的，看有没有老师愿意推荐你，如果找到了老师愿意推荐，那么你九月份就还有一线希望，但不要过于乐观。了解完了之后在12点左右有一个冷餐会，吃点东西就可以走人了。</p>
<h3 id="南京大学计算机夏令营"><a href="#南京大学计算机夏令营" class="headerlink" title="南京大学计算机夏令营"></a>南京大学计算机夏令营</h3><p>清华夏令营结束后回学校休息了两三天，这几天正是高温，也没怎么休息好，7月13号晚上就坐上火车去南京，然后又做了好久的地铁才到，南京大学真是有点偏远。报完到之后就去宿舍休息了，这宾馆十分高档，应该是我住过最高档的。休息了一会儿一个我们学校的本专业同学发来消息问我在哪，问我现在去不去找老师，我想了一会儿就答应了，和他一块去找老师，准备提前联系一下，去了之后他说准备去找lamda（了解的人知道lamda有多牛）的老师，我想都没想过，我觉得有点难吧，我先去和我之前联系的老师见了一下（他不在，和他的博士聊了一会儿），然后有和那个同学去lamda实验室试试，lamda在5月份就有过一次面试，我当时没去，没想到现在听说还有几个名额，就在这下午就准备给大家面试一下，还好我来了，不然又错过机会了，但是来了也有将近10个左右，但是名额不超过4，5个，我们排好队面试。轮到我了，我进去没有自我介绍直接开问，问了几个数学问题，我之前准备的可以，回答这些没任何问题，老师们看起来很满意，然后我又把他们往我喜欢的机器学习等方向上引，让他们问这些方面的问题，因为我也准备的还可以，果然他们问了，结果可想而知，比较满意，一个老师当场就说你那个报名表带来没有，我现在给你签字吧（南大必须要有接受你的老师给你签字，然后再去通过学院的面试就可以了），尴尬，我没带进来，在门口排队时放在袋子里了，想着没必要带进去，没想到老师当场要给我签字，我说我出去拿，他说不要拿不要拿，那就明天早上你在拿来吧，我说好。其实他是不想让外面还在排队的人知道我被接收了，我其实也明白，因为老师们跟之前的同学的回复是你回去等消息吧，我们筛选之后再通知你们，所以我就答应明天早上再拿来签字。出来之后很高兴，没想到lamda这么轻松的就拿到名额了。感觉已经没有问题了（没想到学院面试会很坑），吃完饭高兴的回去了。<br>第二天就是开营仪式，然后就是各个实验室的摆出牌子来宣传，还可以去实验室参观，演示一些研究成果来吸引大家。因为lamda已经接收了，继续了解了一下之后就走了，毕竟已经签字了。<br>第三天就是学院的面试，我是第二个面试，南大不得不说做的很不好，我进去了，共三个老师，之后老师问有没有简历，我开始就没打算给简历的，因为南大在面试之前就说了啥都不用带，直接进去就行了，不让带简历的，我进去之后却张口找我要简历，这不是逗我玩了吗，我在想这老师昨晚喝多了吧！他们说要简历我不得不给要，可是在书包里面，还好我把书包带进去了，但是翻简历过程很尴尬呀，真不知道该咋吐槽。没有要求我做自我介绍又是直接开始问问题，我想也好，但是这个提问老师好像就是软件工程和软件测试的，他上来就直接问我什么是软件工程，只有被问过这个问题的人才了解我此时的心情，之前有个去北航面试的同学也被问过类似的，结果坑死了。我凭着印象简单说了一下，答案不是那么理想，然后第二个问题更加让你欲哭无泪，他问研究软件和研究软件工程有没有什么区别。。。我想郑老师（我一个老师）快来帮我解答一下吧。。。此时的心情没人能理解，我想了一会儿回答说有一定区别，刚说完“有区别”三个字立刻就被他打断了说其实没有多大区别，他扯了一堆理由解释，我在想你这明显就是故意的嘛，这个问题本身就是见仁见智的问题，说出自己的理解就可以了嘛，他却那么快打断我却发表自己的看法。一个旁边的老师看我比较尴尬就打圆场说这应该不是他想选的方向，那个老师也不知道咋说的记不清了，然后又接着说用英文解释一下什么事软件测试，必须英文，没办法憋了一两句解释了一下就不会说了。然后就结束了，感觉不太好。这个过程没问一个数学类或者研究类问题，我想对一个想做研究的人你净问这些虚的模能两可的问题。面试分为很多组，听说其他组都问的很正常很稳，我们这个组被很多人吐槽。说到底还是自己平时对一些常见的基本问题不够重视，计划赶不上变化，平时多积累多了解一点还是没错的。</p>
<h3 id="中科大计算机夏令营"><a href="#中科大计算机夏令营" class="headerlink" title="中科大计算机夏令营"></a>中科大计算机夏令营</h3><p>中科大夏令营是17号开始报道，因为之前联系的老师说提前见个面并且来个机试，所以16号南京大学的夏令营一结束下午立刻就坐上高铁去了中科大，大概5点多到的，有点晚，我去的时候老师已经走了，他的学生说让我晚上8点左右过来，我就先回宾馆了吃完饭休息了一会儿，大概7点40左右我就出发去学校找他，先是给我做一个机试，一共四道题，全是英文的，而且题目十分长废话很多，需要你快速读懂英文题目，总共就小时，不可能做完4题，所以我的计划是抓点紧做完两道就OK了，后来才知道其实做多少不重要，只要能做出一道就可以，因为中科大这四道题没有像其他学校那样给你几道送分题，从第一题开始就涉及到一点点算法。结束之后一个研究生把我叫去了另一个办公室，包括他里面共有三人，有一个是博士（后来了解到这个博士非常优秀），然后他们开始和我聊天（后来才知道其实就是面试，如果过了才会推荐给老师最终面谈一下），聊的范围比较广，从兴趣去爱好到个人的特点再问一些专业知识，还问一些感兴趣的研究方向上的问题，无非就是看看数学的基本功和对该研究方向的了解程度，之前就说过了，这方面我准备的比较充分，没有什么问题，整个过程很轻松。结束之后一看时间有点晚了，我一个人来这里不太熟让我赶紧回宾馆，还说让我找个时间去和老师见一下，也就是让老师最终在看看可不可以，这次聊天大概40到50分钟。结果就是比较满意。然后第二天就是正式报道举行开营仪式，中科大是所有专业同时举办夏令营的，所以好多人，开营仪式非常正式，整个夏令营的活动都非常多，我觉的中科大的夏令营才是真正意义上的夏令营，有学术交流，有休闲娱乐。下午就是师生见面会，副院长也就是我后来的导师做了开场报告，整体介绍了一下各个实验室，然后就是老师和同学们之间做游戏，副院长报告完就又走了不能和我们一起‘玩’，走之前有一个非常有意思的场景，我和我们学校计算机学院的一个女生遇到了，她也是想报这个老师的实验室，跟我说咱们赶紧去和他聊聊，他又要出去开会了，我就和他一起去了，我先和老师说了我是西工大的之前联系他的某某某，他知道我了，然后说好的，那个女生也说我是西工大的某某某，我也是报您的实验室的也说了一番，老师笑了一下，心想这么多西工大的，说我们实验室后面有机试好好准备啥的。我已经做过了，她还没有做。这是一个男生看我们说了这么多，他也出来说我也是西工大的某某某（也是计算机院的），现场师生都笑了，西工大的咋都找这个老师，别急还有，这时又来一个男生跟这个老师说我也是西工大的某某某，同样说了一翻，这场面真少见，真的有意思，看来西工大的想霸占这个实验室啊。。。这次我们学校来了4个，计算机学院1个女生两个男生，软件学院就我一个。老师走后所有学生和其他老师做游戏（有点意思）。在晚上有个别实验室有面试，我去了一个（这个是和我最后想去的实验室应该是是最好的两个实验室了）参加面试，没想到人好多，每个人都发两页英文的纸，上面是他们写过的论文的前两页，基本都不一样，需要你在这短时间内看懂，然后面试轮到你了就去，我看了一会儿，我就感觉我对这个方向不感兴趣，我大看了一下是讲什么的然后就没看了，到我面试了，我进去之后两个老师（人比较亲和）看了我的简历然后问了我一些问题，然后问我这两页纸看的咋样，我大概说了一下，他们就说可以了可以了，说这么短时间能看到这个程度很不错了，整个过程很愉快。然后我就会宿舍了。到宿舍休息了一会儿我就洗澡去了，出来一看手机有一个未接来电，我回了过去，他说是刚才面试的老师，说我面试通过了，如果愿意来这个实验室的话明天来签个双方确认书，我答应了。挂了电话后我很高兴，但是有些纠结。第二天，上午参观先研院和实验室，结束后我就抽空去昨天打电话的老师那里签字，他给我一张纸，我填了一般之后犹豫了，我又问了一下这个实验室的研究方向，我不太感兴趣，场面十分尴尬，老师又给我解释他们是干什么的，但是我依然不感兴趣，手里拿着那张表真不知道咋办，老师看出来了就说你还报了其他实验室吗，我如实说了，我之前联系了做大数据的实验室，我说我想做人工智能方面的，他说那个实验室是做人工智能出身的，但我们实验室实力也挺强的。（这些我都知道，这两个实验室是科大计算机实力最好的两个）我又说我想能不能我明天去那个实验室面试之后再做决定（此时我心里确实不太喜欢这个方向），当然老师也不想做备胎，就说嗯也可以，但是你现在不确认明天我们不能保证有名额给你，因为我们也有备选人，我们现在就提前决定给你名额是因为觉得你比较那啥（你们懂的），我手里拿着确认书，上面写着签了就必须来，所以我当时面临两个选择，一是直接签了确认，我的夏令营就结束了，后面学院面试不出什么大问题就OK了，第二个选择是放弃这个实验室，赌一把，赌我明天和之前联系的老师（副院长）见面比较成功然后去我感兴趣的方向，但风险就是，明天我见面不顺利，那么这两个最好的实验室都没戏，只能去找其他实验室了。我犹豫了好久，而且是在如此尴尬的情况下，当时我和老师都是站着的，最后我思考了很久，做出了决定，我决定赌一把，因为我读研肯定是要选我感兴趣的方向，不然我未来的硕士阶段将过的很不舒服，还不如直接出去工作，最坏的打算大不了夏令营失败了，九月份再战其他学校，我也说不准我的决定是对是错，我想不管对错，适合我的才是最好的，以后的路还长，所以我大胆的决定直接拒绝，我就跟老师说，那算了吧，我在考虑考虑吧，老师也看出来我的想法就说好吧，明天你要想来我们也欢迎但是不能保证给你留名额（我当然知道是套话，肯定没名额，还有那么多候选的），出来之后感觉轻松了许多，刚出门没多久就看到刚刚出去的那个同学又被叫回去了，我拦住问了一下，他是刚才老师让他回去等通知的同学，我一出来老师就给他打电话说实验室筛选好了让他过去签字，我心里很清楚，我一出来名额就让出去了，我的名额给他了。。。我都料到了，也做好了最坏的打算了，而且此时我并不为刚才的决定后悔。这天结束后，我们都回宿舍休息，第三天也就是19号户外活动，参观科大讯飞等地方，晚上我就去找老师见面了，因为他最近去外面开会了比较忙，还是晚上9点多一回办公室我就找的他，我把简历给他，他看了一下然后问了我一些问题，没问太多，了解了一些我的情况，因为我之前就聊过好多了专业问题，如果不行的话他的学生也不会把我推荐给他，最后就结束了，感觉还不错。晚上回去我就问之前微信加的一个学长（这个老师的博士）今晚的结果什么时候出来，他说明天就出来了。过了一会儿就睡了，第二天早上刚下车（科大都是用专车在宾馆和学校之间接送，科大这点做的比较好）之前面试我的博士生打电话给我说我面试通过了。挂完电话我顿时感觉心里的石头落地了，看来昨天博了一把那个选择是对的，然后这一整天就过的很轻松了，都忘记这一天干都是啥活动了，最后一天21号了，学校正式面试开始，时间是一上午，我排在中间，我等前面的等了好久，到我了我进去之后看到有三个老师，两个男老师一个女老师，一个老师让我说一下自己的特点，我巴拉巴拉说了一堆之后老师们对我很认可，两个男老师说嗯不错，很雷厉风行啊，这个特点要保持。然后就问了我一个简单的问题说无向图的深度搜索结果是否唯一，然后就结束，那个女老师就没吭过声，男老师问她还有没有想说的，她说可以了没有了。然后就结束了，感觉好快，瞬间就结束了，一个特点的介绍吸引住了老师后就特别顺利了。下午回去后面试中的两个男老师竟然都打电话过来问我，第一个老师说你联系好老师没有，我今天面试对你印象很好，有没有兴趣来我们这实验室，我当然会拒绝，因为我喜欢的那个实验室已经联系好了，我就委婉的回答，我就说我联系好老师了，他说让我等今天通知出来再决定要不要我（其实已经要我了，我是顺便试探一下我今天的面试过了没有），老师立刻说你已经通过了，你如果没联系好老师可以来我们这里，我说好的谢谢老师，我会考虑的，然后老师说你想来可以打我这个电话，谢谢老师之后就挂了。过了一会儿面试我的第二个老师也打电话来了（这个老师是做系统方向的，也是科大很牛的教授，跟他的一个本科毕业于科大的博士聊天时知道的）说今天非常看好我，问我有没有找好老师，想不想去他那里，我说我找好了，谢谢了老师之后就愉快的挂了电话。心情十分的高兴，没想到这么多老师希望我去他们那里（好多同学都没联系到），并且再次为那一次决定感到高兴，去了自己最想去的实验室。下午两三点实验室老师发来短信说要和我们筛选出来的学生一起见面，我去了后发现包括我在内共五同学，也就是说这次夏令营这个实验室只招了5个人，这次报这个实验室的大概有三四十人，最起码那天我们西工大的四个都找了这个老师的（再次感到那天很有趣），所以说我们还是很幸运的。老师和我们交流了一下，然后散了，吃完饭去参加闭营仪式，办的也十分好，10几个节目的表演，像晚会一样。次日早上也就是22号坐上火车返回西安。这次科大夏令营心情充满波折，过程非常愉快，最后的结果很满意。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>平时在学完课上东西之后还是需要再拓展一下，尤其是在自己感兴趣的方向上深入，否则别人会觉得你自己喜欢的东西都不了解那你还了解啥。</li>
<li>要注意多积累，主要是一些本专业本领域的一些常识性问题要重视，不管是不是你喜欢的专业，既然选了就要好好对待。</li>
<li>然后英语要不要丢掉，学了这么多年不能白学了，尤其是以后做研究搞学术还是需要的，面试的时候虽然不一定会问，但是如果问了就懵了，英语还是要坚持学。</li>
<li>还有就是在面临选择是要坚持自己的意愿，不能被眼前的利益所诱惑，该放弃的要果断放弃，适合自己兴趣的才是最好的。</li>
</ul>

<script src="https://readmore.openwrite.cn/js/readmore.js" type="text/javascript"></script>
<script>
    const btw = new BTWPlugin();
    btw.init({
        id: 'jiedu',
        blogId: '26372-1618624976356-155',
        name: '一切皆可解读',
        qrcode: 'https://img.chsong.live/Blogs/gzh-erweima.png-o',
        keyword: '解锁',
    });
</script>
]]></content>
      <tags>
        <tag>动态</tag>
      </tags>
  </entry>
  <entry>
    <title>大学生活回顾</title>
    <url>/20171226_NWPUReview/index.html</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">您好, 这里需要密码.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="ed21a6bb97c5731d24472096ef52281439896f2a6b27b74067850e4644e08c9a">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机</title>
    <url>/20171014_SVM/index.html</url>
    <content><![CDATA[<p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1507893605639&di=16fad19f6589ac2b2dc8cd4c7d74f1f3&imgtype=0&src=http%3A%2F%2Fsigvc.org%2Fwhy%2Fbook%2F3dp%2Fpaste2.files%2Fimage004.jpg" alt=""></p>
<p>支持向量机（SVM）是一个非常好的监督学习算法，由于这个算法涉及到的数学知识比较多，而且不容易弄懂，因此我额外补了一些拉格朗日对偶性的一些知识，还初步了解了以下凸优化的相关知识，建议如过想学SVM的先去学一些拉格朗日对偶问题以及一些凸优化的相关东西。终于能大致弄懂SVM的整个过程中所涉及到的一些东西，但是仍有一些地方还是不太明白，还有待继续学习。这里先对所掌握的过程进行回顾总结。</p>
<a id="more"></a>

<h2 id="Support-Vector-Machine-SVM"><a href="#Support-Vector-Machine-SVM" class="headerlink" title="Support Vector Machine (SVM)"></a>Support Vector Machine (SVM)</h2><p>支持向量机（SVM）是一个监督学习算法，它实质上是一种特征空间上的间隔最大的线性分类器，这其中涉及到核技巧将线性不可分问题映射成特征空间中的线性可分问题，因此支持向量机可以说是一个非线性分类器，它的学习策略就是间隔最大化，最后的问题可以转化为一个凸优化问题，使用拉格朗日对偶性来求解对偶问题，从而间接得到原问题的解，一般使用SMO算法来求对偶问题的解。</p>
<h3 id="间隔最大化"><a href="#间隔最大化" class="headerlink" title="间隔最大化"></a>间隔最大化</h3><p>支持向量机的思想就是间隔最大化，根据间隔最大化来构造原始问题。这里涉及到的间隔包括函数间隔和几何间隔，其中函数间隔为$\hat \gamma_i$<br>$$<br>\hat \gamma_i = y_i(\omega\cdot x_i + b) \tag{1}<br>$$<br>然后得到所有样本的函数间隔中的最小的一个$$\hat\gamma = \min_{i = 1,\cdots,N}(\hat\gamma_i)$$</p>
<p>几何间隔由空间中两点的实际距离定义记作$\gamma_i$<br>$$<br>\gamma_i = \dfrac{\omega}{||\omega||}\cdot x_i + \dfrac{b}{||\omega||}\tag{2}<br>$$<br>同理求出所有几何间隔最小的$$\gamma = \min_{i =1\cdots,N}(\gamma_i)$$</p>
<p>可以看出函数间隔是不唯一的，因为满足分离超平面$\omega^\ast\cdot x + b^\ast= 0$的参数$(\omega,b)$并不是唯一的，例如将$\omega$和$b$发你别扩大两倍后$2\omega^\ast\cdot x + 2b^\ast = 0$仍然成立，而函数间隔$\hat\gamma$会随着$(\omega , b)$变化。而几何距离却不会发生变化。</p>
<p>同时还可以看出函数间隔和几何间隔之间满足关系(3)<br>$$<br>\gamma = \dfrac{\hat\gamma}{||\omega||}\tag{3}<br>$$<br>因此这里考虑求解几何间隔最大的分离超平面，该问题则表示为下面的约束最优化问题<br>$$<br>\max_{\omega,b} \quad \gamma\tag{4}\\<br>s.t.\quad y_i(\dfrac{\omega}{||\omega||}\cdot x_i + \dfrac{b}{||\omega||}) \ge \gamma,\qquad i = 1,2,\cdots,N<br>$$<br>根据上述关系(3)将问题转换为<br>$$<br>\max_{\omega,b} \quad \dfrac{\hat\gamma}{||\omega||}\tag{5}\\<br>s.t.\quad y_i(\omega\cdot x_i + b) \ge \hat\gamma,\qquad i = 1,2,\cdots,N<br>$$<br>因为函数距离跟随$\omega$和$b$而变化，这里做出限制$\hat\gamma = 1$。而最大化$\dfrac{1}{||\omega||}$和最小化$\dfrac{1}{2}||\omega||^2$是等价的，因此，问题进一步转化为<br>$$<br>\min_{\omega, b}\quad\dfrac{1}{2}||\omega||^2\tag{6}\\<br>s.t.\quad y_i(\omega\cdot x_i + b) \ge 1,\qquad i = 1,2,\cdots,N<br>$$<br>问题(6)就是支持向量机需要解决的问题，即原始最优化问题，最终我们求得的分类决策函数是<br>$$<br>f(x) = \text{sign}(\omega^\ast\cdot x + b^\ast)\tag{7}<br>$$</p>
<h3 id="拉格朗日对偶性"><a href="#拉格朗日对偶性" class="headerlink" title="拉格朗日对偶性"></a>拉格朗日对偶性</h3><p>对上述问题(6)建立拉格朗日函数，引入拉格朗日乘子$\alpha_i \ge 0, \quad i = 1,2,\cdots,N$，定义拉格朗日函数为<br>$$<br>L(\omega,b,\alpha) = \dfrac{1}{2}||\omega||^2 - \sum_{i=1}^N\alpha_iy_i(\omega\cdot x_i + b) + \sum_{i = 1}^N\alpha_i\tag{8}<br>$$<br>分别对$\omega$和$b$求偏导令其为零然后带入到拉格朗日函数(8)中去，即得到其对偶问题(关于对偶的相关知识不在此陈述)<br>$$<br>\min_{\alpha}\quad\dfrac{1}{2}\sum_{i = 1}^{N}\sum_{j = 1}^N\alpha_i\alpha_jy_iy_j(x_i\cdot x_j) - \sum_{i = 1}^N\alpha_i\tag{9}\\<br>s.t.\quad \sum_{i = 1}^N\alpha_iy_i = 0\\<br>\alpha_i \ge 0, \quad i = 1,2,\cdots, N<br>$$<br>然而实际情况中，线性可分的情况是十分少的，一般都是近似线性可分的的，这里涉及到的是软间隔支持向量机，也称为线性支持向量机，是最基本的支持向量机。</p>
<p>对与近似线性可分的样本中的噪声样本通过引入一个松弛变量$\xi_i$，从而使其在一定的可接受的误差范围内可分，因此得到线性支持向量机的原始最优化问题<br>$$<br>\min_{\omega, b}\quad\dfrac{1}{2}||\omega||^2+C\sum_{i = 1}^N\xi_i\tag{10}\\<br>s.t.\quad y_i(\omega\cdot x_i + b) \ge 1 - \xi_i,\qquad i = 1,2,\cdots,N\\<br>\xi_i \ge 0, \quad i = 1,2,\cdots,N<br>$$<br>其对偶问题为<br>$$<br>\min_{\alpha}\quad\dfrac{1}{2}\sum_{i = 1}^{N}\sum_{j = 1}^N\alpha_i\alpha_jy_iy_j(x_i\cdot x_j) - \sum_{i = 1}^N\alpha_i\tag{11}\\<br>s.t.\quad \sum_{i = 1}^N\alpha_iy_i = 0\\<br>0 \le\alpha_i \le C, \quad i = 1,2,\cdots, N<br>$$<br>可一看到，他和线性可分支持向量机的唯一区别是$\alpha_i$的约束多了一个上限。</p>
<h3 id="非线性支持向量机与核技巧"><a href="#非线性支持向量机与核技巧" class="headerlink" title="非线性支持向量机与核技巧"></a>非线性支持向量机与核技巧</h3><p>对于输入空间中的分线性分类问题，可以通过非线性变换将它转换为某个高维特征空间中的线性分类问题，在高维空间中学习线性支持向量机。</p>
<p>输入空间到某个高维空间的转换是通过映射$\phi(x):\chi \to H$来完成的，对于$\forall x,z \in \chi$，函数$K(x,z)$满足条件$K(x,z) = \phi(x)\cdot\phi(z)$，则称函数$K(x,z)$为核函数。</p>
<p>目标函数与分类决策函数中都只涉及实例与实例之间的内积，因此并不需要显示的指定非线性变换，而是直接用核函数来代替内积，对偶问题则变为如下形式<br>$$<br>W(\alpha) = \dfrac{1}{2}\sum_{i = 1}^N\sum_{j = 1}^N\alpha_i\alpha_jy_iy_jK(x_i,x_j) - \sum_{i = 1}^N\alpha_i\tag{12}<br>$$<br>分类决策函数中的内积也用核函数来表示，则<br>$$<br>f(x) = \text{sign}(\sum_{i = 1}^{N_s}\alpha_i^{\ast}y_i\phi(x_i)\cdot\phi(x)+b^\ast) = \text{sign}(\sum_{i = 1}^{N_s}\alpha_i^\ast y_iK(x_i,x)+b^\ast)\tag{13}<br>$$<br>因此在线性支持向量机学习的对偶问题中使用核函数来代替内积即可解得非线性支持向量机。</p>
<h3 id="序列最小最优化算法（SMO）"><a href="#序列最小最优化算法（SMO）" class="headerlink" title="序列最小最优化算法（SMO）"></a>序列最小最优化算法（SMO）</h3><p>该算法分为两个部分分别是</p>
<blockquote>
<p>求解两个变量二次规划的解析方法</p>
<p>选择变量的启发式方法</p>
</blockquote>
<h4 id="两个变量的二次规划解析方法"><a href="#两个变量的二次规划解析方法" class="headerlink" title="两个变量的二次规划解析方法"></a>两个变量的二次规划解析方法</h4><p>假定选择两个变量$\alpha_1$和$\alpha_2$，而其它的变量$\alpha_i(i = 3,4,\cdots,N)$保持不变，则(12)式的子问题可以表示为<br>$$<br>\min_{\alpha_1,\alpha_2}\quad W(\alpha_1,\alpha_2) = \dfrac{1}{2}K_{11}\alpha_1^2+\dfrac{1}{2}K_{22}\alpha_2^2 + y_1y_2K_{12}\alpha_1\alpha_2 \\ \quad\quad\quad- (\alpha_1+\alpha_2) + y_1\alpha_1\sum_{i = 3}^{N}y_i\alpha_iK_{i1} + y_2\alpha_2\sum_{i = 3}^Ny_i\alpha_iK_{i2}\tag{14}\\s.t.\quad \alpha_1y_1 + \alpha_2y_2 = -\sum_{i = 3}^Ny_i\alpha_i = \zeta\\0 \le \alpha\le C,\quad i = 1,2<br>$$<br>将问题(14)中的等式约束$\alpha_1y_1 + \alpha_2y_2 = -\sum_{i = 3}^Ny_i\alpha_i = \zeta$进行变换，用$\alpha_2$来表示$\alpha_1$，将其代入到(14)式中，那么问题就变为关于变量$\alpha_2$的二次函数求极值的问题，求得$\alpha_2$之后通过等式$\alpha_1y_1 + \alpha_2y_2 = -\sum_{i = 3}^Ny_i\alpha_i = \zeta$即可得到$\alpha_1$的值。</p>
<h4 id="启发式变量选择方法"><a href="#启发式变量选择方法" class="headerlink" title="启发式变量选择方法"></a>启发式变量选择方法</h4><p>SMO称第一个变量的选择为外层循环，外层循环在训练样本中选取<code>违反KKT条件最严重</code>的样本点，并将其对应的变量作为第一个变量，具体的检验训练样本$(x_i, y_i)$是否满足KKT条件，即<br>$$<br>\alpha_i = 0 \Leftrightarrow y_i g(x_i) \ge 1\\ 0 \lt \alpha_i \lt C \Leftrightarrow y_ig(x_i) = 1\\ \alpha_i = C \Leftrightarrow y_ig(x_i) \le 1<br>$$<br>其中$g(x_i) = \sum_{j = 1}^N\alpha_jy_jK(x_i,x_j) + b$，改检验是在$\varepsilon$范围内进行的。</p>
<p>第二个变量的选择称为内层循环，在找到第一个变量$\alpha_1$的条件下，在内层循环中寻找第二个变量$\alpha_2$，第二个变量的选择标准是希望能够使$\alpha_2$尽量有足够大的变化。</p>
<p>关于SMO算法中的变量选择方法我目前并不是完全懂，先写到这里为止。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>此次总结对之前学的支持向量机的相关知识进行了一次回顾，支持向量机结合核技巧是一个非常好的学习算法，它利用了拉格朗日问题的对偶性，将原问题转换为对偶问题，因为可能存在一种情况是每个样本的属性非常的多，也就是输入空间的维数非常的大，而转换为对偶问题之后，参数是和样本一一对应的，因此参数数目就是样本的数目，这能够大大减小计算的复杂度，最后对于求解凸二次规划问题有十分有效的SMO算法，因为子问题有解析解，因此每次计算子问题都十分的快，虽然子问题数目多，但是总体上看来还是很快的。</p>
<p><strong>最新精彩内容，请关注微信公众号：一切皆可解读</strong></p>
<p><img src="http://img.chsong.live/Blogs/gzh.jpeg-o" alt=""></p>
]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>算法</tag>
        <tag>科研</tag>
      </tags>
  </entry>
</search>
